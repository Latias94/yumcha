// This file is automatically generated, so please do not edit it.
// @generated by `flutter_rust_bridge`@ 2.10.0.

// ignore_for_file: invalid_use_of_internal_member, unused_import, unnecessary_import

import '../frb_generated.dart';
import 'package:flutter_rust_bridge/flutter_rust_bridge_for_generated.dart';
import 'package:freezed_annotation/freezed_annotation.dart' hide protected;
part 'ai_chat.freezed.dart';

// These functions are ignored because they are not marked as `pub`: `build_chat_options_for_stream`, `build_chat_options`, `build_chat_request`, `create_genai_client`, `fetch_models_from_openai_api`, `get_adapter_kind`, `get_default_base_url`, `normalize_base_url`, `normalize_base_url`, `set_env_api_key`, `should_include_model`, `supports_openai_compatible_api`
// These types are ignored because they are neither used by any `pub` functions nor (for structs and enums) marked `#[frb(unignore)]`: `OpenAiModel`, `OpenAiModelsResponse`
// These function are ignored because they are on traits that is not defined in current crate (put an empty `#[frb]` on it to unignore): `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`

/// 独立的标题生成函数（推荐使用）
Future<TitleGenerationResponse> generateTitleStandalone({
  required AiProvider provider,
  required AiChatOptions options,
  required List<ChatMessage> messages,
  String? customPrompt,
}) => RustLib.instance.api.crateApiAiChatGenerateTitleStandalone(
  provider: provider,
  options: options,
  messages: messages,
  customPrompt: customPrompt,
);

/// 创建AI聊天客户端
AiChatClient createAiChatClient({
  required AiProvider provider,
  required AiChatOptions options,
}) => RustLib.instance.api.crateApiAiChatCreateAiChatClient(
  provider: provider,
  options: options,
);

/// 快速聊天 (使用默认配置)
Future<String> quickChat({
  required AiProvider provider,
  required String model,
  required String apiKey,
  required String message,
}) => RustLib.instance.api.crateApiAiChatQuickChat(
  provider: provider,
  model: model,
  apiKey: apiKey,
  message: message,
);

/// 快速流式聊天
Stream<ChatStreamEvent> quickChatStream({
  required AiProvider provider,
  required String model,
  required String apiKey,
  required String message,
}) => RustLib.instance.api.crateApiAiChatQuickChatStream(
  provider: provider,
  model: model,
  apiKey: apiKey,
  message: message,
);

/// 检查提供商是否支持列出模型
bool checkProviderSupportsListModels({required AiProvider provider}) => RustLib
    .instance
    .api
    .crateApiAiChatCheckProviderSupportsListModels(provider: provider);

/// 获取提供商能力信息
ProviderCapabilities getProviderCapabilitiesInfo({
  required AiProvider provider,
}) => RustLib.instance.api.crateApiAiChatGetProviderCapabilitiesInfo(
  provider: provider,
);

/// 快速获取模型列表（带错误处理）
Future<ModelListResponse> getModelsFromProvider({
  required AiProvider provider,
  required String apiKey,
  String? baseUrl,
}) => RustLib.instance.api.crateApiAiChatGetModelsFromProvider(
  provider: provider,
  apiKey: apiKey,
  baseUrl: baseUrl,
);

/// 直接从 OpenAI 兼容 API 获取模型列表
Future<ModelListResponse> fetchOpenaiCompatibleModels({
  required String apiKey,
  required String baseUrl,
}) => RustLib.instance.api.crateApiAiChatFetchOpenaiCompatibleModels(
  apiKey: apiKey,
  baseUrl: baseUrl,
);

/// 快速生成聊天标题
Future<TitleGenerationResponse> generateChatTitle({
  required AiProvider provider,
  required String model,
  required String apiKey,
  String? baseUrl,
  required List<ChatMessage> messages,
  String? customPrompt,
}) => RustLib.instance.api.crateApiAiChatGenerateChatTitle(
  provider: provider,
  model: model,
  apiKey: apiKey,
  baseUrl: baseUrl,
  messages: messages,
  customPrompt: customPrompt,
);

/// 移除思考类模型的 <think> 标签
Future<String> removeThinkingTags({required String content}) =>
    RustLib.instance.api.crateApiAiChatRemoveThinkingTags(content: content);

/// 清理标题：移除换行符并限制长度
Future<String> cleanTitle({required String title}) =>
    RustLib.instance.api.crateApiAiChatCleanTitle(title: title);

/// 简单的流式测试函数 - 发送一些测试数据
Stream<ChatStreamEvent> testStream() =>
    RustLib.instance.api.crateApiAiChatTestStream();

/// 初始化AI聊天客户端
class AiChatClient {
  final AiProvider provider;
  final AiChatOptions options;

  const AiChatClient.raw({required this.provider, required this.options});

  /// 单次聊天 (非流式)
  Future<ChatResponse> chat({required List<ChatMessage> messages}) => RustLib
      .instance
      .api
      .crateApiAiChatAiChatClientChat(that: this, messages: messages);

  /// 流式聊天
  Stream<ChatStreamEvent> chatStream({required List<ChatMessage> messages}) =>
      RustLib.instance.api.crateApiAiChatAiChatClientChatStream(
        that: this,
        messages: messages,
      );

  /// 生成标题（便捷方法，使用当前客户端的配置）
  Future<TitleGenerationResponse> generateTitle({
    required List<ChatMessage> messages,
    String? customPrompt,
  }) => RustLib.instance.api.crateApiAiChatAiChatClientGenerateTitle(
    that: this,
    messages: messages,
    customPrompt: customPrompt,
  );

  /// 获取支持的模型列表
  Future<List<String>> getAvailableModels() => RustLib.instance.api
      .crateApiAiChatAiChatClientGetAvailableModels(that: this);

  /// 获取支持的模型列表（带错误处理）
  Future<ModelListResponse> getAvailableModelsSafe() => RustLib.instance.api
      .crateApiAiChatAiChatClientGetAvailableModelsSafe(that: this);

  /// 获取提供商能力信息
  ProviderCapabilities getProviderCapabilities() => RustLib.instance.api
      .crateApiAiChatAiChatClientGetProviderCapabilities(that: this);

  /// 创建新的AI聊天客户端
  factory AiChatClient({
    required AiProvider provider,
    required AiChatOptions options,
  }) => RustLib.instance.api.crateApiAiChatAiChatClientNew(
    provider: provider,
    options: options,
  );

  /// 检查提供商是否支持列出模型
  bool supportsListModels() => RustLib.instance.api
      .crateApiAiChatAiChatClientSupportsListModels(that: this);

  @override
  int get hashCode => provider.hashCode ^ options.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is AiChatClient &&
          runtimeType == other.runtimeType &&
          provider == other.provider &&
          options == other.options;
}

/// AI聊天配置选项
class AiChatOptions {
  /// 模型名称 (例如: "gpt-4", "claude-3-haiku-20240307")
  final String model;

  /// 自定义服务器地址 (可选)
  final String? baseUrl;

  /// API密钥
  final String apiKey;

  /// 温度参数 (0.0-2.0)
  final double? temperature;

  /// Top-p参数 (0.0-1.0)
  final double? topP;

  /// 最大生成token数
  final int? maxTokens;

  /// 系统提示词
  final String? systemPrompt;

  /// 停止序列
  final List<String>? stopSequences;

  const AiChatOptions({
    required this.model,
    this.baseUrl,
    required this.apiKey,
    this.temperature,
    this.topP,
    this.maxTokens,
    this.systemPrompt,
    this.stopSequences,
  });

  @override
  int get hashCode =>
      model.hashCode ^
      baseUrl.hashCode ^
      apiKey.hashCode ^
      temperature.hashCode ^
      topP.hashCode ^
      maxTokens.hashCode ^
      systemPrompt.hashCode ^
      stopSequences.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is AiChatOptions &&
          runtimeType == other.runtimeType &&
          model == other.model &&
          baseUrl == other.baseUrl &&
          apiKey == other.apiKey &&
          temperature == other.temperature &&
          topP == other.topP &&
          maxTokens == other.maxTokens &&
          systemPrompt == other.systemPrompt &&
          stopSequences == other.stopSequences;
}

@freezed
sealed class AiProvider with _$AiProvider {
  const AiProvider._();

  const factory AiProvider.openAi() = AiProvider_OpenAI;
  const factory AiProvider.anthropic() = AiProvider_Anthropic;
  const factory AiProvider.cohere() = AiProvider_Cohere;
  const factory AiProvider.gemini() = AiProvider_Gemini;
  const factory AiProvider.groq() = AiProvider_Groq;
  const factory AiProvider.ollama() = AiProvider_Ollama;
  const factory AiProvider.xai() = AiProvider_Xai;
  const factory AiProvider.deepSeek() = AiProvider_DeepSeek;
  const factory AiProvider.custom({required String name}) = AiProvider_Custom;
}

/// 聊天消息内容
class ChatMessage {
  final ChatRole role;
  final String content;

  const ChatMessage({required this.role, required this.content});

  @override
  int get hashCode => role.hashCode ^ content.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is ChatMessage &&
          runtimeType == other.runtimeType &&
          role == other.role &&
          content == other.content;
}

/// 聊天响应
class ChatResponse {
  final String content;
  final String model;
  final TokenUsage? usage;

  const ChatResponse({required this.content, required this.model, this.usage});

  @override
  int get hashCode => content.hashCode ^ model.hashCode ^ usage.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is ChatResponse &&
          runtimeType == other.runtimeType &&
          content == other.content &&
          model == other.model &&
          usage == other.usage;
}

/// 聊天消息角色
enum ChatRole { system, user, assistant }

@freezed
sealed class ChatStreamEvent with _$ChatStreamEvent {
  const ChatStreamEvent._();

  /// 开始流式响应
  const factory ChatStreamEvent.start() = ChatStreamEvent_Start;

  /// 内容块
  const factory ChatStreamEvent.content({required String content}) =
      ChatStreamEvent_Content;

  /// 完成响应
  const factory ChatStreamEvent.done({
    required String totalContent,
    TokenUsage? usage,
  }) = ChatStreamEvent_Done;

  /// 错误
  const factory ChatStreamEvent.error({required String message}) =
      ChatStreamEvent_Error;
}

/// 模型列表响应
class ModelListResponse {
  /// 模型列表
  final List<String> models;

  /// 是否成功
  final bool success;

  /// 错误信息（如果有）
  final String? errorMessage;

  const ModelListResponse({
    required this.models,
    required this.success,
    this.errorMessage,
  });

  @override
  int get hashCode =>
      models.hashCode ^ success.hashCode ^ errorMessage.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is ModelListResponse &&
          runtimeType == other.runtimeType &&
          models == other.models &&
          success == other.success &&
          errorMessage == other.errorMessage;
}

/// 提供商能力信息
class ProviderCapabilities {
  /// 是否支持列出模型
  final bool supportsListModels;

  /// 是否支持自定义服务器地址
  final bool supportsCustomBaseUrl;

  /// 提供商描述
  final String description;

  const ProviderCapabilities({
    required this.supportsListModels,
    required this.supportsCustomBaseUrl,
    required this.description,
  });

  @override
  int get hashCode =>
      supportsListModels.hashCode ^
      supportsCustomBaseUrl.hashCode ^
      description.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is ProviderCapabilities &&
          runtimeType == other.runtimeType &&
          supportsListModels == other.supportsListModels &&
          supportsCustomBaseUrl == other.supportsCustomBaseUrl &&
          description == other.description;
}

/// 专门用于标题生成的客户端
class TitleGenerationClient {
  final AiProvider provider;
  final AiChatOptions options;

  const TitleGenerationClient.raw({
    required this.provider,
    required this.options,
  });

  /// 从现有的聊天客户端创建标题生成客户端
  static TitleGenerationClient fromChatClient({
    required AiChatClient chatClient,
  }) => RustLib.instance.api.crateApiAiChatTitleGenerationClientFromChatClient(
    chatClient: chatClient,
  );

  /// 生成标题
  Future<TitleGenerationResponse> generateTitle({
    required List<ChatMessage> messages,
    String? customPrompt,
  }) => RustLib.instance.api.crateApiAiChatTitleGenerationClientGenerateTitle(
    that: this,
    messages: messages,
    customPrompt: customPrompt,
  );

  /// 创建标题生成客户端
  factory TitleGenerationClient({
    required AiProvider provider,
    required AiChatOptions options,
  }) => RustLib.instance.api.crateApiAiChatTitleGenerationClientNew(
    provider: provider,
    options: options,
  );

  @override
  int get hashCode => provider.hashCode ^ options.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is TitleGenerationClient &&
          runtimeType == other.runtimeType &&
          provider == other.provider &&
          options == other.options;
}

/// 标题生成响应
class TitleGenerationResponse {
  final String title;
  final bool success;
  final String? errorMessage;

  const TitleGenerationResponse({
    required this.title,
    required this.success,
    this.errorMessage,
  });

  @override
  int get hashCode => title.hashCode ^ success.hashCode ^ errorMessage.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is TitleGenerationResponse &&
          runtimeType == other.runtimeType &&
          title == other.title &&
          success == other.success &&
          errorMessage == other.errorMessage;
}

/// Token使用情况
class TokenUsage {
  final int? promptTokens;
  final int? completionTokens;
  final int? totalTokens;

  const TokenUsage({
    this.promptTokens,
    this.completionTokens,
    this.totalTokens,
  });

  @override
  int get hashCode =>
      promptTokens.hashCode ^ completionTokens.hashCode ^ totalTokens.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is TokenUsage &&
          runtimeType == other.runtimeType &&
          promptTokens == other.promptTokens &&
          completionTokens == other.completionTokens &&
          totalTokens == other.totalTokens;
}
