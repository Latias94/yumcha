// This file is automatically generated, so please do not edit it.
// @generated by `flutter_rust_bridge`@ 2.10.0.

// ignore_for_file: invalid_use_of_internal_member, unused_import, unnecessary_import

import '../frb_generated.dart';
import 'package:flutter_rust_bridge/flutter_rust_bridge_for_generated.dart';
import 'package:freezed_annotation/freezed_annotation.dart' hide protected;
part 'ai_chat.freezed.dart';

// These functions are ignored because they are not marked as `pub`: `build_chat_options_for_stream`, `build_chat_options`, `build_chat_request`, `create_genai_client`, `get_adapter_kind`, `normalize_base_url`, `set_env_api_key`
// These function are ignored because they are on traits that is not defined in current crate (put an empty `#[frb]` on it to unignore): `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `clone`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`, `fmt`

/// 创建AI聊天客户端
AiChatClient createAiChatClient({
  required AiProvider provider,
  required AiChatOptions options,
}) => RustLib.instance.api.crateApiAiChatCreateAiChatClient(
  provider: provider,
  options: options,
);

/// 快速聊天 (使用默认配置)
Future<String> quickChat({
  required AiProvider provider,
  required String model,
  required String apiKey,
  required String message,
}) => RustLib.instance.api.crateApiAiChatQuickChat(
  provider: provider,
  model: model,
  apiKey: apiKey,
  message: message,
);

/// 快速流式聊天
Stream<ChatStreamEvent> quickChatStream({
  required AiProvider provider,
  required String model,
  required String apiKey,
  required String message,
}) => RustLib.instance.api.crateApiAiChatQuickChatStream(
  provider: provider,
  model: model,
  apiKey: apiKey,
  message: message,
);

/// 简单的流式测试函数 - 发送一些测试数据
Stream<ChatStreamEvent> testStream() =>
    RustLib.instance.api.crateApiAiChatTestStream();

/// 初始化AI聊天客户端
class AiChatClient {
  final AiProvider provider;
  final AiChatOptions options;

  const AiChatClient.raw({required this.provider, required this.options});

  /// 单次聊天 (非流式)
  Future<ChatResponse> chat({required List<ChatMessage> messages}) => RustLib
      .instance
      .api
      .crateApiAiChatAiChatClientChat(that: this, messages: messages);

  /// 流式聊天
  Stream<ChatStreamEvent> chatStream({required List<ChatMessage> messages}) =>
      RustLib.instance.api.crateApiAiChatAiChatClientChatStream(
        that: this,
        messages: messages,
      );

  /// 获取支持的模型列表
  Future<List<String>> getAvailableModels() => RustLib.instance.api
      .crateApiAiChatAiChatClientGetAvailableModels(that: this);

  /// 创建新的AI聊天客户端
  factory AiChatClient({
    required AiProvider provider,
    required AiChatOptions options,
  }) => RustLib.instance.api.crateApiAiChatAiChatClientNew(
    provider: provider,
    options: options,
  );

  @override
  int get hashCode => provider.hashCode ^ options.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is AiChatClient &&
          runtimeType == other.runtimeType &&
          provider == other.provider &&
          options == other.options;
}

/// AI聊天配置选项
class AiChatOptions {
  /// 模型名称 (例如: "gpt-4", "claude-3-haiku-20240307")
  final String model;

  /// 自定义服务器地址 (可选)
  final String? baseUrl;

  /// API密钥
  final String apiKey;

  /// 温度参数 (0.0-2.0)
  final double? temperature;

  /// Top-p参数 (0.0-1.0)
  final double? topP;

  /// 最大生成token数
  final int? maxTokens;

  /// 系统提示词
  final String? systemPrompt;

  /// 停止序列
  final List<String>? stopSequences;

  const AiChatOptions({
    required this.model,
    this.baseUrl,
    required this.apiKey,
    this.temperature,
    this.topP,
    this.maxTokens,
    this.systemPrompt,
    this.stopSequences,
  });

  @override
  int get hashCode =>
      model.hashCode ^
      baseUrl.hashCode ^
      apiKey.hashCode ^
      temperature.hashCode ^
      topP.hashCode ^
      maxTokens.hashCode ^
      systemPrompt.hashCode ^
      stopSequences.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is AiChatOptions &&
          runtimeType == other.runtimeType &&
          model == other.model &&
          baseUrl == other.baseUrl &&
          apiKey == other.apiKey &&
          temperature == other.temperature &&
          topP == other.topP &&
          maxTokens == other.maxTokens &&
          systemPrompt == other.systemPrompt &&
          stopSequences == other.stopSequences;
}

@freezed
sealed class AiProvider with _$AiProvider {
  const AiProvider._();

  const factory AiProvider.openAi() = AiProvider_OpenAI;
  const factory AiProvider.anthropic() = AiProvider_Anthropic;
  const factory AiProvider.cohere() = AiProvider_Cohere;
  const factory AiProvider.gemini() = AiProvider_Gemini;
  const factory AiProvider.groq() = AiProvider_Groq;
  const factory AiProvider.ollama() = AiProvider_Ollama;
  const factory AiProvider.xai() = AiProvider_Xai;
  const factory AiProvider.deepSeek() = AiProvider_DeepSeek;
  const factory AiProvider.custom({required String name}) = AiProvider_Custom;
}

/// 聊天消息内容
class ChatMessage {
  final ChatRole role;
  final String content;

  const ChatMessage({required this.role, required this.content});

  @override
  int get hashCode => role.hashCode ^ content.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is ChatMessage &&
          runtimeType == other.runtimeType &&
          role == other.role &&
          content == other.content;
}

/// 聊天响应
class ChatResponse {
  final String content;
  final String model;
  final TokenUsage? usage;

  const ChatResponse({required this.content, required this.model, this.usage});

  @override
  int get hashCode => content.hashCode ^ model.hashCode ^ usage.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is ChatResponse &&
          runtimeType == other.runtimeType &&
          content == other.content &&
          model == other.model &&
          usage == other.usage;
}

/// 聊天消息角色
enum ChatRole { system, user, assistant }

@freezed
sealed class ChatStreamEvent with _$ChatStreamEvent {
  const ChatStreamEvent._();

  /// 开始流式响应
  const factory ChatStreamEvent.start() = ChatStreamEvent_Start;

  /// 内容块
  const factory ChatStreamEvent.content({required String content}) =
      ChatStreamEvent_Content;

  /// 完成响应
  const factory ChatStreamEvent.done({
    required String totalContent,
    TokenUsage? usage,
  }) = ChatStreamEvent_Done;

  /// 错误
  const factory ChatStreamEvent.error({required String message}) =
      ChatStreamEvent_Error;
}

/// Token使用情况
class TokenUsage {
  final int? promptTokens;
  final int? completionTokens;
  final int? totalTokens;

  const TokenUsage({
    this.promptTokens,
    this.completionTokens,
    this.totalTokens,
  });

  @override
  int get hashCode =>
      promptTokens.hashCode ^ completionTokens.hashCode ^ totalTokens.hashCode;

  @override
  bool operator ==(Object other) =>
      identical(this, other) ||
      other is TokenUsage &&
          runtimeType == other.runtimeType &&
          promptTokens == other.promptTokens &&
          completionTokens == other.completionTokens &&
          totalTokens == other.totalTokens;
}
