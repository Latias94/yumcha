import 'dart:async';
import '../../../../../features/ai_management/domain/entities/ai_assistant.dart';
import '../../../../../features/ai_management/domain/entities/ai_provider.dart'
    as models;
import '../../../../../features/chat/domain/entities/message.dart';
import '../../../../../features/settings/domain/usecases/manage_mcp_server_usecase.dart';
import '../core/ai_response_models.dart';
import '../core/ai_service_base.dart';
import 'package:llm_dart/llm_dart.dart';

/// èŠå¤©æœåŠ¡ - AIå¯¹è¯åŠŸèƒ½çš„æ ¸å¿ƒå®ç°
///
/// ChatServiceæ˜¯æ•´ä¸ªAIèŠå¤©ç³»ç»Ÿçš„æ ¸å¿ƒæœåŠ¡ï¼Œè´Ÿè´£å¤„ç†æ‰€æœ‰ä¸AIå¯¹è¯ç›¸å…³çš„åŠŸèƒ½ï¼š
///
/// ## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½
///
/// ### 1. å•æ¬¡èŠå¤©å¯¹è¯
/// - å‘é€æ¶ˆæ¯å¹¶ç­‰å¾…å®Œæ•´å“åº”
/// - æ”¯æŒæ–‡æœ¬ã€å›¾åƒç­‰å¤šæ¨¡æ€è¾“å…¥
/// - è‡ªåŠ¨å¤„ç†ä¸Šä¸‹æ–‡å’Œå†å²æ¶ˆæ¯
///
/// ### 2. æµå¼èŠå¤©å¯¹è¯
/// - å®æ—¶æ¥æ”¶AIå“åº”æµ
/// - æ”¯æŒæ€è€ƒè¿‡ç¨‹å±•ç¤º
/// - æ”¯æŒå·¥å…·è°ƒç”¨è¿›åº¦æ˜¾ç¤º
///
/// ### 3. æä¾›å•†ç®¡ç†
/// - ç»Ÿä¸€ä¸åŒAIæä¾›å•†çš„æ¥å£
/// - è‡ªåŠ¨é€‚é…æä¾›å•†ç‰¹æ€§
/// - æä¾›å•†è¿æ¥æµ‹è¯•å’ŒéªŒè¯
///
/// ### 4. æ€§èƒ½ç›‘æ§
/// - è¯·æ±‚å“åº”æ—¶é—´ç»Ÿè®¡
/// - æˆåŠŸç‡å’Œé”™è¯¯ç‡è·Ÿè¸ª
/// - è¯¦ç»†çš„æ—¥å¿—è®°å½•
///
/// ## ğŸ—ï¸ æ¶æ„è®¾è®¡
///
/// ```
/// ChatService
/// â”œâ”€â”€ AiProviderAdapter    # æä¾›å•†é€‚é…å±‚
/// â”‚   â”œâ”€â”€ OpenAI Adapter
/// â”‚   â”œâ”€â”€ Anthropic Adapter
/// â”‚   â””â”€â”€ Other Adapters
/// â”œâ”€â”€ Statistics Tracker   # ç»Ÿè®¡ä¿¡æ¯æ”¶é›†
/// â””â”€â”€ Request Context      # è¯·æ±‚ä¸Šä¸‹æ–‡ç®¡ç†
/// ```
///
/// ## ğŸ”§ æ”¯æŒçš„AIèƒ½åŠ›
/// - âœ… **chat**: åŸºç¡€èŠå¤©å¯¹è¯
/// - âœ… **streaming**: æµå¼å“åº”
/// - âœ… **toolCalling**: å·¥å…·è°ƒç”¨
/// - âœ… **reasoning**: æ¨ç†æ€è€ƒ
/// - âœ… **vision**: è§†è§‰ç†è§£
///
/// ## ğŸ“Š æ€§èƒ½ç‰¹æ€§
/// - **é€‚é…å™¨ç¼“å­˜**: å¤ç”¨æä¾›å•†é€‚é…å™¨å®ä¾‹
/// - **è¯·æ±‚ç»Ÿè®¡**: å®æ—¶æ”¶é›†æ€§èƒ½æ•°æ®
/// - **é”™è¯¯æ¢å¤**: è‡ªåŠ¨é‡è¯•å’Œé”™è¯¯å¤„ç†
/// - **èµ„æºç®¡ç†**: è‡ªåŠ¨æ¸…ç†è¿æ¥å’Œç¼“å­˜
///
/// ## ğŸš€ ä½¿ç”¨ç¤ºä¾‹
///
/// ### å•æ¬¡èŠå¤©
/// ```dart
/// final response = await chatService.sendMessage(
///   provider: openaiProvider,
///   assistant: chatAssistant,
///   modelName: 'gpt-4',
///   chatHistory: previousMessages,
///   userMessage: 'Hello!',
/// );
/// ```
///
/// ### æµå¼èŠå¤©
/// ```dart
/// await for (final event in chatService.sendMessageStream(...)) {
///   if (event.isContent) {
///     updateUI(event.contentDelta);
///   }
/// }
/// ```
///
/// ### æä¾›å•†æµ‹è¯•
/// ```dart
/// final isWorking = await chatService.testProvider(
///   provider: provider,
///   modelName: 'gpt-3.5-turbo',
/// );
/// ```
class ChatService extends AiServiceBase {
  // å•ä¾‹æ¨¡å¼å®ç° - ç¡®ä¿å…¨å±€å”¯ä¸€çš„èŠå¤©æœåŠ¡å®ä¾‹
  static final ChatService _instance = ChatService._internal();
  factory ChatService() => _instance;
  ChatService._internal();

  /// æä¾›å•†é€‚é…å™¨ç¼“å­˜
  ///
  /// ç¼“å­˜å·²åˆ›å»ºçš„é€‚é…å™¨å®ä¾‹ä»¥æå‡æ€§èƒ½ã€‚ç¼“å­˜é”®æ ¼å¼ï¼š
  /// `{providerId}_{assistantId}_{modelName}`
  ///
  /// è¿™æ ·å¯ä»¥ï¼š
  /// - ğŸš€ **æå‡æ€§èƒ½**ï¼šé¿å…é‡å¤åˆ›å»ºé€‚é…å™¨
  /// - ğŸ’¾ **èŠ‚çœå†…å­˜**ï¼šå¤ç”¨ç›¸åŒé…ç½®çš„é€‚é…å™¨
  /// - ğŸ”„ **ä¿æŒçŠ¶æ€**ï¼šç»´æŠ¤é€‚é…å™¨çš„å†…éƒ¨çŠ¶æ€
  final Map<String, AiProviderAdapter> _adapters = {};

  /// æœåŠ¡ç»Ÿè®¡ä¿¡æ¯ç¼“å­˜
  ///
  /// æŒ‰æä¾›å•†IDå­˜å‚¨ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
  /// - ğŸ“Š **è¯·æ±‚ç»Ÿè®¡**ï¼šæ€»è¯·æ±‚æ•°ã€æˆåŠŸæ•°ã€å¤±è´¥æ•°
  /// - â±ï¸ **æ€§èƒ½æ•°æ®**ï¼šå¹³å‡å“åº”æ—¶é—´ã€æœ€é•¿/æœ€çŸ­è€—æ—¶
  /// - ğŸ•’ **æ—¶é—´ä¿¡æ¯**ï¼šæœ€åè¯·æ±‚æ—¶é—´ã€æœåŠ¡å¯åŠ¨æ—¶é—´
  final Map<String, AiServiceStats> _stats = {};

  /// MCPæœåŠ¡ç®¡ç†å™¨
  final ManageMcpServerUseCase _mcpService = ManageMcpServerUseCase();

  /// æœåŠ¡åˆå§‹åŒ–çŠ¶æ€æ ‡è®°
  bool _isInitialized = false;

  @override
  String get serviceName => 'ChatService';

  @override
  Set<AiCapability> get supportedCapabilities => {
        AiCapability.chat, // åŸºç¡€èŠå¤©å¯¹è¯
        AiCapability.streaming, // æµå¼å“åº”
        AiCapability.toolCalling, // å·¥å…·è°ƒç”¨
        AiCapability.reasoning, // æ¨ç†æ€è€ƒ
        AiCapability.vision, // è§†è§‰ç†è§£
      };

  @override
  Future<void> initialize() async {
    if (_isInitialized) return;

    logger.info('åˆå§‹åŒ–èŠå¤©æœåŠ¡');
    _isInitialized = true;
    logger.info('èŠå¤©æœåŠ¡åˆå§‹åŒ–å®Œæˆ');
  }

  @override
  Future<void> dispose() async {
    logger.info('æ¸…ç†èŠå¤©æœåŠ¡èµ„æº');
    _adapters.clear();
    _stats.clear();
    _isInitialized = false;
  }

  /// å‘é€èŠå¤©æ¶ˆæ¯
  Future<AiResponse> sendMessage({
    required models.AiProvider provider,
    required AiAssistant assistant,
    required String modelName,
    required List<Message> chatHistory,
    required String userMessage,
  }) async {
    await initialize();

    final requestId = _generateRequestId();
    final context = AiRequestContext(
      requestId: requestId,
      config: AiServiceConfig(
        providerId: provider.id,
        modelName: modelName,
        enableStreaming: false,
      ),
    );

    logger.info('å¼€å§‹èŠå¤©è¯·æ±‚', {
      'requestId': requestId,
      'provider': provider.name,
      'model': modelName,
      'assistant': assistant.name,
    });

    try {
      // è·å–æˆ–åˆ›å»ºé€‚é…å™¨
      final adapter = await _getOrCreateAdapter(provider, assistant, modelName);

      // åˆ›å»ºæä¾›å•†å®ä¾‹
      final chatProvider = await adapter.createProvider(enableStreaming: false);

      // æ„å»ºæ¶ˆæ¯åˆ—è¡¨
      final messages = _buildMessageList(adapter, chatHistory, userMessage);

      // è·å–MCPå·¥å…·ï¼ˆå¦‚æœåŠ©æ‰‹å¯ç”¨äº†å·¥å…·åŠŸèƒ½ï¼‰
      final tools = assistant.enableTools
          ? await _getMcpTools(assistant.mcpServerIds)
          : <Tool>[];

      // å‘é€è¯·æ±‚
      final response = await chatProvider.chatWithTools(messages, tools);

      final duration = context.elapsed;

      // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
      _updateStats(provider.id, true, duration);

      logger.info('èŠå¤©è¯·æ±‚å®Œæˆ', {
        'requestId': requestId,
        'duration': '${duration.inMilliseconds}ms',
        'hasThinking': response.thinking != null,
        'usage': response.usage?.totalTokens,
      });

      return AiResponse.success(
        content: response.text ?? '',
        thinking: response.thinking,
        usage: response.usage,
        duration: duration,
        toolCalls: response.toolCalls,
      );
    } catch (e) {
      final duration = context.elapsed;
      _updateStats(provider.id, false, duration);

      logger.error('èŠå¤©è¯·æ±‚å¤±è´¥', {
        'requestId': requestId,
        'error': e.toString(),
        'duration': '${duration.inMilliseconds}ms',
      });

      return AiResponse.error(error: 'èŠå¤©è¯·æ±‚å¤±è´¥: $e', duration: duration);
    }
  }

  /// å‘é€æµå¼èŠå¤©æ¶ˆæ¯
  Stream<AiStreamEvent> sendMessageStream({
    required models.AiProvider provider,
    required AiAssistant assistant,
    required String modelName,
    required List<Message> chatHistory,
    required String userMessage,
  }) async* {
    await initialize();

    final requestId = _generateRequestId();
    final context = AiRequestContext(
      requestId: requestId,
      config: AiServiceConfig(
        providerId: provider.id,
        modelName: modelName,
        enableStreaming: true,
      ),
    );

    logger.info('å¼€å§‹æµå¼èŠå¤©è¯·æ±‚', {
      'requestId': requestId,
      'provider': provider.name,
      'model': modelName,
      'assistant': assistant.name,
    });

    try {
      // è·å–æˆ–åˆ›å»ºé€‚é…å™¨
      final adapter = await _getOrCreateAdapter(provider, assistant, modelName);

      // åˆ›å»ºæµå¼æä¾›å•†å®ä¾‹
      final chatProvider = await adapter.createProvider(enableStreaming: true);

      // æ–°APIä¸­æ‰€æœ‰ChatCapabilityéƒ½æ”¯æŒæµå¼èŠå¤©
      // ä¸éœ€è¦é¢å¤–çš„ç±»å‹æ£€æŸ¥

      // æ„å»ºæ¶ˆæ¯åˆ—è¡¨
      final messages = _buildMessageList(adapter, chatHistory, userMessage);

      // å‘é€æµå¼è¯·æ±‚
      final stream = chatProvider.chatStream(messages);

      String? finalThinking;
      List<ToolCall>? allToolCalls;

      await for (final event in stream) {
        switch (event) {
          case TextDeltaEvent(delta: final delta):
            yield AiStreamEvent.contentDelta(delta);
            break;
          case ThinkingDeltaEvent(delta: final delta):
            yield AiStreamEvent.thinkingDelta(delta);
            break;
          case ToolCallDeltaEvent(toolCall: final toolCall):
            yield AiStreamEvent.toolCall(toolCall);
            allToolCalls ??= [];
            allToolCalls.add(toolCall);
            break;
          case CompletionEvent(response: final response):
            finalThinking = response.thinking;
            final duration = context.elapsed;

            _updateStats(provider.id, true, duration);

            logger.info('æµå¼èŠå¤©è¯·æ±‚å®Œæˆ', {
              'requestId': requestId,
              'duration': '${duration.inMilliseconds}ms',
              'hasThinking': finalThinking != null,
              'usage': response.usage?.totalTokens,
            });

            yield AiStreamEvent.completed(
              finalThinking: finalThinking,
              usage: response.usage,
              duration: duration,
              allToolCalls: allToolCalls,
            );
            break;
          case ErrorEvent(error: final error):
            final duration = context.elapsed;
            _updateStats(provider.id, false, duration);

            logger.error('æµå¼èŠå¤©è¯·æ±‚å‡ºé”™', {
              'requestId': requestId,
              'error': error.toString(),
              'duration': '${duration.inMilliseconds}ms',
            });

            yield AiStreamEvent.error(error.toString());
            break;
        }
      }
    } catch (e) {
      final duration = context.elapsed;
      _updateStats(provider.id, false, duration);

      logger.error('æµå¼èŠå¤©è¯·æ±‚å¤±è´¥', {
        'requestId': requestId,
        'error': e.toString(),
        'duration': '${duration.inMilliseconds}ms',
      });

      yield AiStreamEvent.error('æµå¼èŠå¤©è¯·æ±‚å¤±è´¥: $e');
    }
  }

  /// æµ‹è¯•æä¾›å•†è¿æ¥
  Future<bool> testProvider({
    required models.AiProvider provider,
    String? modelName,
  }) async {
    await initialize();

    try {
      // åˆ›å»ºæµ‹è¯•åŠ©æ‰‹
      final testAssistant = _createTestAssistant();
      final testModel = modelName ?? _getDefaultModel(provider);

      // åˆ›å»ºé€‚é…å™¨
      final adapter = DefaultAiProviderAdapter(
        provider: provider,
        assistant: testAssistant,
        modelName: testModel,
      );

      // åˆ›å»ºæä¾›å•†å®ä¾‹
      final chatProvider = await adapter.createProvider();

      // å‘é€æµ‹è¯•æ¶ˆæ¯
      final testMessages = [ChatMessage.user('Hello')];
      final response = await chatProvider.chatWithTools(testMessages, null);

      logger.info('æä¾›å•†æµ‹è¯•æˆåŠŸ', {
        'provider': provider.name,
        'model': testModel,
        'responseLength': response.text?.length ?? 0,
      });

      return response.text?.isNotEmpty == true;
    } catch (e) {
      logger.error('æä¾›å•†æµ‹è¯•å¤±è´¥', {
        'provider': provider.name,
        'error': e.toString(),
      });
      return false;
    }
  }

  /// è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯
  AiServiceStats getStats(String providerId) {
    return _stats[providerId] ?? AiServiceStats();
  }

  /// è·å–æˆ–åˆ›å»ºé€‚é…å™¨
  Future<AiProviderAdapter> _getOrCreateAdapter(
    models.AiProvider provider,
    AiAssistant assistant,
    String modelName,
  ) async {
    final key = '${provider.id}_${assistant.id}_$modelName';

    if (!_adapters.containsKey(key)) {
      _adapters[key] = DefaultAiProviderAdapter(
        provider: provider,
        assistant: assistant,
        modelName: modelName,
      );
    }

    return _adapters[key]!;
  }

  /// æ„å»ºæ¶ˆæ¯åˆ—è¡¨
  List<ChatMessage> _buildMessageList(
    AiProviderAdapter adapter,
    List<Message> chatHistory,
    String userMessage,
  ) {
    final messages = <ChatMessage>[];

    // æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
    messages.addAll(adapter.buildSystemMessages());

    // æ·»åŠ èŠå¤©å†å²
    messages.addAll(adapter.convertMessages(chatHistory));

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    messages.add(ChatMessage.user(userMessage));

    return messages;
  }

  /// åˆ›å»ºæµ‹è¯•åŠ©æ‰‹
  AiAssistant _createTestAssistant() {
    return AiAssistant(
      id: 'test-assistant',
      name: 'Test Assistant',
      avatar: 'ğŸ¤–',
      systemPrompt: '',
      temperature: 0.7,
      topP: 1.0,
      maxTokens: 10,
      contextLength: 1,
      streamOutput: false,
      isEnabled: true,
      createdAt: DateTime.now(),
      updatedAt: DateTime.now(),
      description: 'Test assistant for provider validation',
      customHeaders: {},
      customBody: {},
      stopSequences: [],
      frequencyPenalty: 0.0,
      presencePenalty: 0.0,
      enableCodeExecution: false,
      enableImageGeneration: false,
      enableTools: false,
      enableReasoning: false,
      enableVision: false,
      enableEmbedding: false,
    );
  }

  /// è·å–æä¾›å•†çš„ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹ä½œä¸ºé»˜è®¤æ¨¡å‹
  String _getDefaultModel(models.AiProvider provider) {
    // å¦‚æœæä¾›å•†æœ‰é…ç½®çš„æ¨¡å‹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª
    if (provider.models.isNotEmpty) {
      return provider.models.first.name;
    }

    // å¦åˆ™æ ¹æ®æä¾›å•†ç±»å‹è¿”å›å¸¸è§çš„æ¨¡å‹å
    switch (provider.type.name.toLowerCase()) {
      case 'openai':
        return 'gpt-3.5-turbo';
      case 'anthropic':
        return 'claude-3-5-sonnet-20241022';
      case 'google':
        return 'gemini-1.5-flash';
      case 'deepseek':
        return 'deepseek-chat';
      case 'ollama':
        return 'llama3.1';
      case 'xai':
        return 'grok-2-latest';
      case 'groq':
        return 'llama3-8b-8192';
      default:
        return 'default-model';
    }
  }

  /// æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
  void _updateStats(String providerId, bool success, Duration duration) {
    final currentStats = _stats[providerId] ?? AiServiceStats();

    _stats[providerId] = currentStats.copyWith(
      totalRequests: currentStats.totalRequests + 1,
      successfulRequests: success
          ? currentStats.successfulRequests + 1
          : currentStats.successfulRequests,
      failedRequests: success
          ? currentStats.failedRequests
          : currentStats.failedRequests + 1,
      totalDuration: currentStats.totalDuration + duration,
      lastRequestTime: DateTime.now(),
    );
  }

  /// ç”Ÿæˆè¯·æ±‚ID
  String _generateRequestId() {
    return 'chat_${DateTime.now().millisecondsSinceEpoch}_${_stats.length}';
  }

  /// è·å–MCPå·¥å…·åˆ—è¡¨
  ///
  /// @param mcpServerIds åŠ©æ‰‹é…ç½®çš„MCPæœåŠ¡å™¨IDåˆ—è¡¨
  /// @returns å¯ç”¨çš„MCPå·¥å…·åˆ—è¡¨ï¼Œè½¬æ¢ä¸ºllm_dartçš„Toolæ ¼å¼
  Future<List<Tool>> _getMcpTools(List<String> mcpServerIds) async {
    // TODO: å®ç°MCPå·¥å…·é›†æˆ
    // å½“å‰è¿”å›ç©ºåˆ—è¡¨ï¼Œå¾…MCPæœåŠ¡å®Œå…¨é›†æˆåå®ç°
    logger.info('MCPå·¥å…·é›†æˆå¾…å®ç°', {
      'serverIds': mcpServerIds,
    });
    return [];
  }
}
