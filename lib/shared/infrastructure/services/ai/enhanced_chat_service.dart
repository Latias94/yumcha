import 'dart:typed_data';
import '../../../../features/chat/domain/entities/message.dart';
import '../../../../features/chat/domain/entities/enhanced_message.dart';
import '../../../../features/chat/domain/entities/legacy_message.dart';
import '../../../../features/ai_management/domain/entities/ai_assistant.dart';
import '../../../../features/ai_management/domain/entities/ai_provider.dart' as models;
import '../media/media_storage_service.dart';
import 'ai_service_manager.dart';
import '../logger_service.dart';

/// å¢å¼ºèŠå¤©æœåŠ¡ - é›†æˆå¤šåª’ä½“åŠŸèƒ½çš„AIèŠå¤©æœåŠ¡
///
/// âš ï¸ **å·²å¼ƒç”¨ (DEPRECATED)** âš ï¸
///
/// è¿™ä¸ªæœåŠ¡å·²è¢« `BlockBasedChatService` æ›¿ä»£ï¼Œè¯·ä½¿ç”¨æ–°çš„å—åŒ–æ¶ˆæ¯ç³»ç»Ÿã€‚
/// æ–°ç³»ç»Ÿæä¾›äº†æ›´å¥½çš„æ¶æ„å’Œæ›´å¼ºå¤§çš„åŠŸèƒ½ï¼š
///
/// - ğŸ§© **å—åŒ–æ¶ˆæ¯æ¶æ„** - æ›´çµæ´»çš„å†…å®¹ç»„ç»‡
/// - ğŸ¨ **å¤šåª’ä½“å—æ”¯æŒ** - ç‹¬ç«‹çš„å¤šåª’ä½“å†…å®¹ç®¡ç†
/// - ğŸ”„ **æµå¼å—æ›´æ–°** - æ›´å¥½çš„å®æ—¶ä½“éªŒ
/// - ğŸ“Š **ç²¾ç»†åŒ–çŠ¶æ€ç®¡ç†** - æ¯ä¸ªå—ç‹¬ç«‹çš„çŠ¶æ€è·Ÿè¸ª
///
/// ## è¿ç§»æŒ‡å—
///
/// è¯·å‚è€ƒ `docs/enhanced_to_block_migration_guide.md` äº†è§£å¦‚ä½•è¿ç§»åˆ°æ–°ç³»ç»Ÿã€‚
///
/// ### æ›¿ä»£æ–¹æ¡ˆ
/// - ä½¿ç”¨ `BlockBasedChatService` æ›¿ä»£æ­¤æœåŠ¡
/// - ä½¿ç”¨ `blockChatProvider` æ›¿ä»£ `enhancedChatProvider`
/// - ä½¿ç”¨ `Message` å’Œ `MessageBlock` æ›¿ä»£ `EnhancedMessage`
///
/// ## åŸæœ‰åŠŸèƒ½ï¼ˆå·²è¿ç§»åˆ°æ–°ç³»ç»Ÿï¼‰
///
/// ### 1. æ™ºèƒ½å†…å®¹æ£€æµ‹ âœ å—åŒ–å†…å®¹è¯†åˆ«
/// - æ£€æµ‹ç”¨æˆ·è¯·æ±‚ä¸­çš„å›¾ç‰‡ç”Ÿæˆæ„å›¾
/// - è¯†åˆ«éœ€è¦TTSçš„æ–‡æœ¬å†…å®¹
/// - åˆ†æä¸Šä¼ çš„å›¾ç‰‡å†…å®¹
///
/// ### 2. è‡ªåŠ¨å¤šåª’ä½“ç”Ÿæˆ âœ å¤šåª’ä½“å—ç”Ÿæˆ
/// - AIå›å¤åŒ…å«å›¾ç‰‡æ—¶è‡ªåŠ¨ç”Ÿæˆ
/// - é•¿æ–‡æœ¬è‡ªåŠ¨ç”ŸæˆTTSéŸ³é¢‘
/// - å¤šåª’ä½“å†…å®¹æ™ºèƒ½å­˜å‚¨
///
/// ### 3. å¢å¼ºæ¶ˆæ¯å¤„ç† âœ å—åŒ–æ¶ˆæ¯å¤„ç†
/// - åˆ›å»ºåŒ…å«å¤šåª’ä½“çš„å—åŒ–æ¶ˆæ¯
/// - è‡ªåŠ¨ç®¡ç†å¤šåª’ä½“æ–‡ä»¶ç”Ÿå‘½å‘¨æœŸ
/// - æ”¯æŒå¤šåª’ä½“å†…å®¹çš„å¯¼å…¥å¯¼å‡º
///
/// @deprecated ä½¿ç”¨ BlockBasedChatService æ›¿ä»£
@Deprecated('ä½¿ç”¨ BlockBasedChatService æ›¿ä»£ã€‚å‚è€ƒ docs/enhanced_to_block_migration_guide.md')
class EnhancedChatService {
  final AiServiceManager _serviceManager;
  final MediaStorageService _mediaService;
  final LoggerService _logger = LoggerService();

  // å›¾ç‰‡ç”Ÿæˆå…³é”®è¯æ£€æµ‹
  static const List<String> _imageGenerationKeywords = [
    'ç”»', 'ç»˜åˆ¶', 'ç”Ÿæˆå›¾ç‰‡', 'åˆ›å»ºå›¾åƒ', 'åˆ¶ä½œå›¾ç‰‡', 'è®¾è®¡å›¾ç‰‡',
    'ç”»ä¸€å¼ ', 'ç”»ä¸ª', 'ç”»å‡º', 'ç”Ÿæˆä¸€å¼ ', 'åˆ›ä½œå›¾ç‰‡', 'åˆ¶ä½œæµ·æŠ¥',
    'draw', 'paint', 'create image', 'generate image', 'make picture',
    'design', 'illustrate', 'sketch', 'render'
  ];

  // TTSç”Ÿæˆé˜ˆå€¼å’Œå…³é”®è¯
  static const int _ttsTextLengthThreshold = 100; // è¶…è¿‡100å­—ç¬¦è‡ªåŠ¨ç”ŸæˆTTS
  static const List<String> _ttsRequestKeywords = [
    'è¯»å‡ºæ¥', 'æœ—è¯»', 'è¯­éŸ³æ’­æ”¾', 'å¿µç»™æˆ‘å¬', 'ç”¨è¯­éŸ³è¯´',
    'read aloud', 'speak', 'voice', 'audio', 'tts'
  ];

  EnhancedChatService({
    required AiServiceManager serviceManager,
    required MediaStorageService mediaService,
  }) : _serviceManager = serviceManager,
       _mediaService = mediaService;

  /// å‘é€å¢å¼ºèŠå¤©æ¶ˆæ¯ï¼ˆæ”¯æŒå¤šåª’ä½“ç”Ÿæˆï¼‰
  Future<EnhancedMessage> sendEnhancedMessage({
    required models.AiProvider provider,
    required AiAssistant assistant,
    required String modelName,
    required List<Message> chatHistory,
    required String userMessage,
    bool autoGenerateImages = true,
    bool autoGenerateTts = true,
    bool enableImageAnalysis = true,
  }) async {
    final startTime = DateTime.now();
    final requestId = _generateRequestId();

    _logger.info('å¼€å§‹å¢å¼ºèŠå¤©è¯·æ±‚', {
      'requestId': requestId,
      'provider': provider.name,
      'model': modelName,
      'autoGenerateImages': autoGenerateImages,
      'autoGenerateTts': autoGenerateTts,
    });

    try {
      // 1. æ£€æµ‹ç”¨æˆ·æ¶ˆæ¯ä¸­çš„å›¾ç‰‡ç”Ÿæˆè¯·æ±‚
      final shouldGenerateImage = autoGenerateImages && 
          _detectImageGenerationIntent(userMessage);

      // 2. å‘é€åŸºç¡€èŠå¤©è¯·æ±‚
      final chatResponse = await _serviceManager.sendMessage(
        provider: provider,
        assistant: assistant,
        modelName: modelName,
        chatHistory: chatHistory,
        userMessage: userMessage,
      );

      if (!chatResponse.isSuccess) {
        // å¦‚æœèŠå¤©å¤±è´¥ï¼Œè¿”å›é”™è¯¯æ¶ˆæ¯
        return EnhancedMessage(
          author: assistant.name,
          content: chatResponse.error ?? 'èŠå¤©è¯·æ±‚å¤±è´¥',
          timestamp: DateTime.now(),
          isFromUser: false,
          status: LegacyMessageStatus.error,
          errorInfo: chatResponse.error,
        );
      }

      final aiContent = chatResponse.content;
      final mediaFiles = <MediaMetadata>[];

      // 3. å¤„ç†å›¾ç‰‡ç”Ÿæˆ
      if (shouldGenerateImage) {
        try {
          final imageMetadata = await _generateImageFromResponse(
            provider: provider,
            aiResponse: aiContent,
            userPrompt: userMessage,
          );
          if (imageMetadata != null) {
            mediaFiles.add(imageMetadata);
          }
        } catch (e) {
          _logger.warning('å›¾ç‰‡ç”Ÿæˆå¤±è´¥', {
            'requestId': requestId,
            'error': e.toString(),
          });
        }
      }

      // 4. å¤„ç†TTSç”Ÿæˆ
      if (autoGenerateTts && _shouldGenerateTts(aiContent, userMessage)) {
        try {
          final audioMetadata = await _generateTtsFromResponse(
            provider: provider,
            text: aiContent,
            voice: null, // ä½¿ç”¨é»˜è®¤è¯­éŸ³
          );
          if (audioMetadata != null) {
            mediaFiles.add(audioMetadata);
          }
        } catch (e) {
          _logger.warning('TTSç”Ÿæˆå¤±è´¥', {
            'requestId': requestId,
            'error': e.toString(),
          });
        }
      }

      // 5. åˆ›å»ºå¢å¼ºæ¶ˆæ¯
      final enhancedMessage = EnhancedMessage.withMedia(
        author: assistant.name,
        content: aiContent,
        timestamp: DateTime.now(),
        isFromUser: false,
        duration: DateTime.now().difference(startTime),
        mediaFiles: mediaFiles,
      );

      _logger.info('å¢å¼ºèŠå¤©è¯·æ±‚å®Œæˆ', {
        'requestId': requestId,
        'duration': '${DateTime.now().difference(startTime).inMilliseconds}ms',
        'mediaFilesCount': mediaFiles.length,
        'hasImages': enhancedMessage.hasImages,
        'hasAudio': enhancedMessage.hasAudio,
      });

      return enhancedMessage;

    } catch (e) {
      _logger.error('å¢å¼ºèŠå¤©è¯·æ±‚å¤±è´¥', {
        'requestId': requestId,
        'error': e.toString(),
      });

      return EnhancedMessage(
        author: assistant.name,
        content: 'æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é”™è¯¯ã€‚',
        timestamp: DateTime.now(),
        isFromUser: false,
        status: LegacyMessageStatus.error,
        errorInfo: e.toString(),
      );
    }
  }

  /// æµå¼å‘é€å¢å¼ºèŠå¤©æ¶ˆæ¯
  Stream<EnhancedMessage> sendEnhancedMessageStream({
    required models.AiProvider provider,
    required AiAssistant assistant,
    required String modelName,
    required List<Message> chatHistory,
    required String userMessage,
    bool autoGenerateImages = true,
    bool autoGenerateTts = true,
  }) async* {
    final requestId = _generateRequestId();
    final startTime = DateTime.now();

    _logger.info('å¼€å§‹å¢å¼ºæµå¼èŠå¤©è¯·æ±‚', {
      'requestId': requestId,
      'provider': provider.name,
      'model': modelName,
    });

    try {
      // æ£€æµ‹æ˜¯å¦éœ€è¦ç”Ÿæˆå›¾ç‰‡
      final shouldGenerateImage = autoGenerateImages && 
          _detectImageGenerationIntent(userMessage);

      var accumulatedContent = '';
      var finalMessage = EnhancedMessage(
        author: assistant.name,
        content: '',
        timestamp: DateTime.now(),
        isFromUser: false,
        status: LegacyMessageStatus.streaming,
      );

      // å‘é€æµå¼èŠå¤©è¯·æ±‚
      await for (final event in _serviceManager.sendMessageStream(
        provider: provider,
        assistant: assistant,
        modelName: modelName,
        chatHistory: chatHistory,
        userMessage: userMessage,
      )) {
        if (event.isContent) {
          accumulatedContent += event.contentDelta ?? '';
          finalMessage = finalMessage.copyWith(
            content: accumulatedContent,
          );
          yield finalMessage;
        } else if (event.isCompleted) {
          // æµå¼å®Œæˆï¼Œå¼€å§‹å¤„ç†å¤šåª’ä½“å†…å®¹
          final mediaFiles = <MediaMetadata>[];

          // å¤„ç†å›¾ç‰‡ç”Ÿæˆ
          if (shouldGenerateImage) {
            try {
              final imageMetadata = await _generateImageFromResponse(
                provider: provider,
                aiResponse: accumulatedContent,
                userPrompt: userMessage,
              );
              if (imageMetadata != null) {
                mediaFiles.add(imageMetadata);
              }
            } catch (e) {
              _logger.warning('æµå¼èŠå¤©å›¾ç‰‡ç”Ÿæˆå¤±è´¥', {
                'requestId': requestId,
                'error': e.toString(),
              });
            }
          }

          // å¤„ç†TTSç”Ÿæˆ
          if (autoGenerateTts && _shouldGenerateTts(accumulatedContent, userMessage)) {
            try {
              final audioMetadata = await _generateTtsFromResponse(
                provider: provider,
                text: accumulatedContent,
                voice: null, // ä½¿ç”¨é»˜è®¤è¯­éŸ³
              );
              if (audioMetadata != null) {
                mediaFiles.add(audioMetadata);
              }
            } catch (e) {
              _logger.warning('æµå¼èŠå¤©TTSç”Ÿæˆå¤±è´¥', {
                'requestId': requestId,
                'error': e.toString(),
              });
            }
          }

          // å‘é€æœ€ç»ˆçš„å¢å¼ºæ¶ˆæ¯
          finalMessage = finalMessage.copyWith(
            status: LegacyMessageStatus.normal,
            mediaFiles: mediaFiles,
            duration: DateTime.now().difference(startTime),
          );

          yield finalMessage;
        } else if (event.isError) {
          yield finalMessage.copyWith(
            status: LegacyMessageStatus.error,
            errorInfo: event.error,
          );
        }
      }

    } catch (e) {
      _logger.error('å¢å¼ºæµå¼èŠå¤©è¯·æ±‚å¤±è´¥', {
        'requestId': requestId,
        'error': e.toString(),
      });

      yield EnhancedMessage(
        author: assistant.name,
        content: 'æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é”™è¯¯ã€‚',
        timestamp: DateTime.now(),
        isFromUser: false,
        status: LegacyMessageStatus.error,
        errorInfo: e.toString(),
      );
    }
  }

  /// åˆ†æå›¾ç‰‡å†…å®¹
  Future<EnhancedMessage> analyzeImage({
    required models.AiProvider provider,
    required AiAssistant assistant,
    required String modelName,
    required Uint8List imageData,
    required String prompt,
    String? fileName,
  }) async {
    final requestId = _generateRequestId();
    final startTime = DateTime.now();

    _logger.info('å¼€å§‹å›¾ç‰‡åˆ†æ', {
      'requestId': requestId,
      'provider': provider.name,
      'model': modelName,
      'imageSize': imageData.length,
    });

    try {
      // 1. å­˜å‚¨ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡
      final imageMetadata = await _mediaService.storeMedia(
        data: imageData,
        fileName: fileName ?? 'user_image_${DateTime.now().millisecondsSinceEpoch}.jpg',
        mimeType: 'image/jpeg',
        customProperties: {
          'type': 'user_upload',
          'analysis_prompt': prompt,
        },
      );

      // 2. ä½¿ç”¨å¤šæ¨¡æ€æœåŠ¡åˆ†æå›¾ç‰‡
      final analysisResponse = await _serviceManager.multimodalService.analyzeImage(
        provider: provider,
        assistant: assistant,
        modelName: modelName,
        imageData: imageData,
        prompt: prompt,
      );

      if (!analysisResponse.isSuccess) {
        return EnhancedMessage(
          author: assistant.name,
          content: 'å›¾ç‰‡åˆ†æå¤±è´¥: ${analysisResponse.error}',
          timestamp: DateTime.now(),
          isFromUser: false,
          status: LegacyMessageStatus.error,
          errorInfo: analysisResponse.error,
          mediaFiles: [imageMetadata],
        );
      }

      // 3. æ£€æŸ¥æ˜¯å¦éœ€è¦ç”ŸæˆTTS
      final mediaFiles = [imageMetadata];
      if (_shouldGenerateTts(analysisResponse.content, prompt)) {
        try {
          final audioMetadata = await _generateTtsFromResponse(
            provider: provider,
            text: analysisResponse.content,
            voice: null, // ä½¿ç”¨é»˜è®¤è¯­éŸ³
          );
          if (audioMetadata != null) {
            mediaFiles.add(audioMetadata);
          }
        } catch (e) {
          _logger.warning('å›¾ç‰‡åˆ†æTTSç”Ÿæˆå¤±è´¥', {
            'requestId': requestId,
            'error': e.toString(),
          });
        }
      }

      // 4. åˆ›å»ºå¢å¼ºæ¶ˆæ¯
      final enhancedMessage = EnhancedMessage.withMedia(
        author: assistant.name,
        content: analysisResponse.content,
        timestamp: DateTime.now(),
        isFromUser: false,
        duration: DateTime.now().difference(startTime),
        mediaFiles: mediaFiles,
      );

      _logger.info('å›¾ç‰‡åˆ†æå®Œæˆ', {
        'requestId': requestId,
        'duration': '${DateTime.now().difference(startTime).inMilliseconds}ms',
        'responseLength': analysisResponse.content.length,
      });

      return enhancedMessage;

    } catch (e) {
      _logger.error('å›¾ç‰‡åˆ†æå¤±è´¥', {
        'requestId': requestId,
        'error': e.toString(),
      });

      return EnhancedMessage(
        author: assistant.name,
        content: 'æŠ±æ­‰ï¼Œå›¾ç‰‡åˆ†ææ—¶å‡ºç°äº†é”™è¯¯ã€‚',
        timestamp: DateTime.now(),
        isFromUser: false,
        status: LegacyMessageStatus.error,
        errorInfo: e.toString(),
      );
    }
  }

  // ç§æœ‰è¾…åŠ©æ–¹æ³•

  /// æ£€æµ‹ç”¨æˆ·æ¶ˆæ¯ä¸­çš„å›¾ç‰‡ç”Ÿæˆæ„å›¾
  bool _detectImageGenerationIntent(String userMessage) {
    final lowerMessage = userMessage.toLowerCase();
    return _imageGenerationKeywords.any((keyword) =>
        lowerMessage.contains(keyword.toLowerCase()));
  }

  /// åˆ¤æ–­æ˜¯å¦åº”è¯¥ç”ŸæˆTTS
  bool _shouldGenerateTts(String aiResponse, String userMessage) {
    // 1. ç”¨æˆ·æ˜ç¡®è¯·æ±‚è¯­éŸ³
    final lowerUserMessage = userMessage.toLowerCase();
    if (_ttsRequestKeywords.any((keyword) =>
        lowerUserMessage.contains(keyword.toLowerCase()))) {
      return true;
    }

    // 2. AIå›å¤æ–‡æœ¬è¾ƒé•¿
    if (aiResponse.length > _ttsTextLengthThreshold) {
      return true;
    }

    // 3. å›å¤åŒ…å«è¯—æ­Œã€æ•…äº‹ç­‰é€‚åˆæœ—è¯»çš„å†…å®¹
    final lowerResponse = aiResponse.toLowerCase();
    final narrativeKeywords = ['æ•…äº‹', 'è¯—æ­Œ', 'è¯—', 'ç«¥è¯', 'å°è¯´', 'story', 'poem', 'tale'];
    if (narrativeKeywords.any((keyword) =>
        lowerResponse.contains(keyword.toLowerCase()))) {
      return true;
    }

    return false;
  }

  /// ä»AIå›å¤ç”Ÿæˆå›¾ç‰‡
  Future<MediaMetadata?> _generateImageFromResponse({
    required models.AiProvider provider,
    required String aiResponse,
    required String userPrompt,
  }) async {
    try {
      // æ£€æŸ¥æä¾›å•†æ˜¯å¦æ”¯æŒå›¾ç‰‡ç”Ÿæˆ
      final imageService = _serviceManager.imageGenerationService;
      if (!imageService.supportsImageGeneration(provider)) {
        _logger.debug('æä¾›å•†ä¸æ”¯æŒå›¾ç‰‡ç”Ÿæˆ', {'provider': provider.name});
        return null;
      }

      // æå–æˆ–ç”Ÿæˆå›¾ç‰‡æè¿°
      final imagePrompt = _extractImagePrompt(userPrompt, aiResponse);
      if (imagePrompt.isEmpty) {
        return null;
      }

      // ç”Ÿæˆå›¾ç‰‡
      final imageResponse = await imageService.generateImage(
        provider: provider,
        prompt: imagePrompt,
        size: '1024x1024',
        quality: 'standard',
        count: 1,
      );

      if (!imageResponse.isSuccess || imageResponse.images.isEmpty) {
        _logger.warning('å›¾ç‰‡ç”Ÿæˆå¤±è´¥', {
          'prompt': imagePrompt,
          'error': imageResponse.error,
        });
        return null;
      }

      final generatedImage = imageResponse.images.first;

      // ä¸‹è½½å¹¶å­˜å‚¨å›¾ç‰‡
      if (generatedImage.url != null) {
        try {
          // è¿™é‡Œéœ€è¦å®é™…ä¸‹è½½å›¾ç‰‡æ•°æ®
          // æš‚æ—¶ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
          final imageData = Uint8List.fromList([]);

          return await _mediaService.storeMedia(
            data: imageData,
            fileName: 'ai_generated_${DateTime.now().millisecondsSinceEpoch}.png',
            mimeType: 'image/png',
            networkUrl: generatedImage.url,
            customProperties: {
              'type': 'ai_generated',
              'prompt': imagePrompt,
              'revised_prompt': generatedImage.revisedPrompt,
              'generation_time': DateTime.now().toIso8601String(),
            },
          );
        } catch (e) {
          _logger.error('å­˜å‚¨AIç”Ÿæˆå›¾ç‰‡å¤±è´¥', {'error': e.toString()});
          return null;
        }
      }

      return null;
    } catch (e) {
      _logger.error('ç”Ÿæˆå›¾ç‰‡å¤±è´¥', {'error': e.toString()});
      return null;
    }
  }

  /// ä»AIå›å¤ç”ŸæˆTTSéŸ³é¢‘
  Future<MediaMetadata?> _generateTtsFromResponse({
    required models.AiProvider provider,
    required String text,
    String? voice,
  }) async {
    try {
      // æ£€æŸ¥æä¾›å•†æ˜¯å¦æ”¯æŒTTS
      final multimodalService = _serviceManager.multimodalService;
      if (!_supportsTts(provider)) {
        _logger.debug('æä¾›å•†ä¸æ”¯æŒTTS', {'provider': provider.name});
        return null;
      }

      // æ¸…ç†æ–‡æœ¬ï¼ˆç§»é™¤markdownæ ‡è®°ç­‰ï¼‰
      final cleanText = _cleanTextForTts(text);
      if (cleanText.isEmpty) {
        return null;
      }

      // ç”ŸæˆTTSéŸ³é¢‘
      final ttsResponse = await multimodalService.textToSpeech(
        provider: provider,
        text: cleanText,
        voice: voice ?? 'alloy',
      );

      if (!ttsResponse.isSuccess || ttsResponse.audioData.isEmpty) {
        _logger.warning('TTSç”Ÿæˆå¤±è´¥', {
          'textLength': cleanText.length,
          'error': ttsResponse.error,
        });
        return null;
      }

      // å­˜å‚¨éŸ³é¢‘
      return await _mediaService.storeMedia(
        data: ttsResponse.audioData,
        fileName: 'tts_${DateTime.now().millisecondsSinceEpoch}.mp3',
        mimeType: 'audio/mpeg',
        cacheExpiry: const Duration(days: 7),
        customProperties: {
          'type': 'tts_generated',
          'text_length': cleanText.length,
          'voice': voice ?? 'alloy',
          'generation_time': DateTime.now().toIso8601String(),
        },
      );
    } catch (e) {
      _logger.error('ç”ŸæˆTTSå¤±è´¥', {'error': e.toString()});
      return null;
    }
  }

  /// æå–å›¾ç‰‡ç”Ÿæˆæç¤ºè¯
  String _extractImagePrompt(String userPrompt, String aiResponse) {
    // 1. å¦‚æœç”¨æˆ·æ¶ˆæ¯åŒ…å«æ˜ç¡®çš„å›¾ç‰‡æè¿°ï¼Œä½¿ç”¨ç”¨æˆ·çš„æè¿°
    final userLower = userPrompt.toLowerCase();
    for (final keyword in _imageGenerationKeywords) {
      if (userLower.contains(keyword.toLowerCase())) {
        // æå–å…³é”®è¯åçš„æè¿°
        final index = userLower.indexOf(keyword.toLowerCase());
        if (index != -1) {
          final afterKeyword = userPrompt.substring(index + keyword.length).trim();
          if (afterKeyword.isNotEmpty) {
            return afterKeyword;
          }
        }
      }
    }

    // 2. ä»AIå›å¤ä¸­æå–å›¾ç‰‡æè¿°
    final lines = aiResponse.split('\n');
    for (final line in lines) {
      final trimmed = line.trim();
      if (trimmed.length > 20 && trimmed.length < 200) {
        // ç®€å•çš„å¯å‘å¼ï¼šé€‰æ‹©ä¸­ç­‰é•¿åº¦çš„æè¿°æ€§å¥å­
        if (trimmed.contains('å›¾ç‰‡') || trimmed.contains('ç”»é¢') ||
            trimmed.contains('åœºæ™¯') || trimmed.contains('image')) {
          return trimmed;
        }
      }
    }

    // 3. ä½¿ç”¨ç”¨æˆ·åŸå§‹æç¤ºä½œä¸ºåå¤‡
    return userPrompt.length > 200 ? userPrompt.substring(0, 200) : userPrompt;
  }

  /// æ¸…ç†æ–‡æœ¬ç”¨äºTTS
  String _cleanTextForTts(String text) {
    // ç§»é™¤markdownæ ‡è®°
    var cleaned = text
        .replaceAll(RegExp(r'\*\*(.*?)\*\*'), r'$1') // ç²—ä½“
        .replaceAll(RegExp(r'\*(.*?)\*'), r'$1')     // æ–œä½“
        .replaceAll(RegExp(r'`(.*?)`'), r'$1')       // ä»£ç 
        .replaceAll(RegExp(r'#{1,6}\s*'), '')        // æ ‡é¢˜
        .replaceAll(RegExp(r'\[(.*?)\]\(.*?\)'), r'$1') // é“¾æ¥
        .replaceAll(RegExp(r'!\[.*?\]\(.*?\)'), '')  // å›¾ç‰‡
        .replaceAll(RegExp(r'```[\s\S]*?```'), '')   // ä»£ç å—
        .replaceAll(RegExp(r'`[^`]*`'), '');         // è¡Œå†…ä»£ç 

    // ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    cleaned = cleaned
        .replaceAll(RegExp(r'\n\s*\n'), '\n')
        .replaceAll(RegExp(r'\s+'), ' ')
        .trim();

    // é™åˆ¶é•¿åº¦ï¼ˆTTSé€šå¸¸æœ‰å­—ç¬¦é™åˆ¶ï¼‰
    if (cleaned.length > 4000) {
      cleaned = cleaned.substring(0, 4000);
      // å°è¯•åœ¨å¥å·å¤„æˆªæ–­
      final lastPeriod = cleaned.lastIndexOf('ã€‚');
      if (lastPeriod > 3000) {
        cleaned = cleaned.substring(0, lastPeriod + 1);
      }
    }

    return cleaned;
  }

  /// æ£€æŸ¥æä¾›å•†æ˜¯å¦æ”¯æŒTTS
  bool _supportsTts(models.AiProvider provider) {
    switch (provider.type.name.toLowerCase()) {
      case 'openai':
      case 'elevenlabs':
        return true;
      default:
        return false;
    }
  }

  /// ç”Ÿæˆè¯·æ±‚ID
  String _generateRequestId() {
    return 'enhanced_chat_${DateTime.now().millisecondsSinceEpoch}_${(DateTime.now().microsecond % 1000).toString().padLeft(3, '0')}';
  }
}
