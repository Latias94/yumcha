import 'dart:async';
import 'dart:typed_data';
import '../../../../../features/ai_management/domain/entities/ai_provider.dart' as models;
import '../../../../../features/ai_management/domain/entities/ai_assistant.dart';
import '../core/ai_service_base.dart';
import 'package:ai_dart/ai_dart.dart';

/// è¯­éŸ³æœåŠ¡ï¼Œè´Ÿè´£å¤„ç†TTSå’ŒSTTåŠŸèƒ½
class SpeechService extends AiServiceBase {
  static final SpeechService _instance = SpeechService._internal();
  factory SpeechService() => _instance;
  SpeechService._internal();

  final Map<String, Uint8List> _ttsCache = {};
  final Map<String, String> _sttCache = {};
  final Map<String, DateTime> _cacheTimestamps = {};
  static const Duration _cacheExpiry = Duration(hours: 1);
  bool _isInitialized = false;

  @override
  String get serviceName => 'SpeechService';

  @override
  Set<AiCapability> get supportedCapabilities => {
    AiCapability.textToSpeech,
    AiCapability.speechToText,
  };

  @override
  Future<void> initialize() async {
    if (_isInitialized) return;

    logger.info('åˆå§‹åŒ–è¯­éŸ³æœåŠ¡');
    _isInitialized = true;
    logger.info('è¯­éŸ³æœåŠ¡åˆå§‹åŒ–å®Œæˆ');
  }

  @override
  Future<void> dispose() async {
    logger.info('æ¸…ç†è¯­éŸ³æœåŠ¡èµ„æº');
    _ttsCache.clear();
    _sttCache.clear();
    _cacheTimestamps.clear();
    _isInitialized = false;
  }

  /// æ–‡å­—è½¬è¯­éŸ³
  Future<Uint8List> textToSpeech({
    required models.AiProvider provider,
    required String text,
    String? voice,
    bool useCache = true,
  }) async {
    await initialize();

    final cacheKey = _generateTtsCacheKey(provider.id, text, voice);

    // æ£€æŸ¥ç¼“å­˜
    if (useCache && _isTtsCacheValid(cacheKey)) {
      logger.debug('ä»ç¼“å­˜è·å–TTSéŸ³é¢‘', {
        'provider': provider.name,
        'textLength': text.length,
        'voice': voice,
      });
      return _ttsCache[cacheKey]!;
    }

    logger.info('ç”ŸæˆTTSéŸ³é¢‘', {
      'provider': provider.name,
      'textLength': text.length,
      'voice': voice,
    });

    try {
      // åˆ›å»ºä¸´æ—¶åŠ©æ‰‹
      final tempAssistant = _createTempAssistant();

      // åˆ›å»ºé€‚é…å™¨
      final adapter = DefaultAiProviderAdapter(
        provider: provider,
        assistant: tempAssistant,
        modelName: _getTtsModel(provider),
      );

      // åˆ›å»ºæä¾›å•†å®ä¾‹
      final chatProvider = await adapter.createProvider();

      // æ£€æŸ¥æ˜¯å¦æ”¯æŒTTSåŠŸèƒ½
      if (chatProvider is! TextToSpeechCapability) {
        throw Exception('æä¾›å•†ä¸æ”¯æŒTTSåŠŸèƒ½: ${provider.name}');
      }

      final ttsProvider = chatProvider as TextToSpeechCapability;
      final audioBytes = await ttsProvider.speech(text);
      final audioData = Uint8List.fromList(audioBytes);

      // æ›´æ–°ç¼“å­˜
      _ttsCache[cacheKey] = audioData;
      _cacheTimestamps[cacheKey] = DateTime.now();

      logger.info('TTSéŸ³é¢‘ç”Ÿæˆå®Œæˆ', {
        'provider': provider.name,
        'textLength': text.length,
        'audioSize': audioData.length,
      });

      return audioData;
    } catch (e) {
      logger.error('TTSéŸ³é¢‘ç”Ÿæˆå¤±è´¥', {
        'provider': provider.name,
        'error': e.toString(),
      });
      rethrow;
    }
  }

  /// è¯­éŸ³è½¬æ–‡å­—
  Future<String> speechToText({
    required models.AiProvider provider,
    required Uint8List audioData,
    bool useCache = true,
  }) async {
    await initialize();

    final cacheKey = _generateSttCacheKey(provider.id, audioData);

    // æ£€æŸ¥ç¼“å­˜
    if (useCache && _isSttCacheValid(cacheKey)) {
      logger.debug('ä»ç¼“å­˜è·å–STTæ–‡æœ¬', {
        'provider': provider.name,
        'audioSize': audioData.length,
      });
      return _sttCache[cacheKey]!;
    }

    logger.info('è½¬æ¢è¯­éŸ³ä¸ºæ–‡å­—', {
      'provider': provider.name,
      'audioSize': audioData.length,
    });

    try {
      // åˆ›å»ºä¸´æ—¶åŠ©æ‰‹
      final tempAssistant = _createTempAssistant();

      // åˆ›å»ºé€‚é…å™¨
      final adapter = DefaultAiProviderAdapter(
        provider: provider,
        assistant: tempAssistant,
        modelName: _getSttModel(provider),
      );

      // åˆ›å»ºæä¾›å•†å®ä¾‹
      final chatProvider = await adapter.createProvider();

      // æ£€æŸ¥æ˜¯å¦æ”¯æŒSTTåŠŸèƒ½
      if (chatProvider is! SpeechToTextCapability) {
        throw Exception('æä¾›å•†ä¸æ”¯æŒSTTåŠŸèƒ½: ${provider.name}');
      }

      final sttProvider = chatProvider as SpeechToTextCapability;
      final transcription = await sttProvider.transcribe(audioData);

      // æ›´æ–°ç¼“å­˜
      _sttCache[cacheKey] = transcription;
      _cacheTimestamps[cacheKey] = DateTime.now();

      logger.info('STTè½¬æ¢å®Œæˆ', {
        'provider': provider.name,
        'audioSize': audioData.length,
        'textLength': transcription.length,
      });

      return transcription;
    } catch (e) {
      logger.error('STTè½¬æ¢å¤±è´¥', {
        'provider': provider.name,
        'error': e.toString(),
      });
      rethrow;
    }
  }

  /// ä»æ–‡ä»¶è·¯å¾„è¿›è¡Œè¯­éŸ³è½¬æ–‡å­—
  Future<String> speechToTextFromFile({
    required models.AiProvider provider,
    required String filePath,
    bool useCache = true,
  }) async {
    await initialize();

    logger.info('ä»æ–‡ä»¶è½¬æ¢è¯­éŸ³ä¸ºæ–‡å­—', {
      'provider': provider.name,
      'filePath': filePath,
    });

    try {
      // åˆ›å»ºä¸´æ—¶åŠ©æ‰‹
      final tempAssistant = _createTempAssistant();

      // åˆ›å»ºé€‚é…å™¨
      final adapter = DefaultAiProviderAdapter(
        provider: provider,
        assistant: tempAssistant,
        modelName: _getSttModel(provider),
      );

      // åˆ›å»ºæä¾›å•†å®ä¾‹
      final chatProvider = await adapter.createProvider();

      // æ£€æŸ¥æ˜¯å¦æ”¯æŒSTTåŠŸèƒ½
      if (chatProvider is! SpeechToTextCapability) {
        throw Exception('æä¾›å•†ä¸æ”¯æŒSTTåŠŸèƒ½: ${provider.name}');
      }

      final sttProvider = chatProvider as SpeechToTextCapability;
      final transcription = await sttProvider.transcribeFile(filePath);

      logger.info('æ–‡ä»¶STTè½¬æ¢å®Œæˆ', {
        'provider': provider.name,
        'filePath': filePath,
        'textLength': transcription.length,
      });

      return transcription;
    } catch (e) {
      logger.error('æ–‡ä»¶STTè½¬æ¢å¤±è´¥', {
        'provider': provider.name,
        'error': e.toString(),
      });
      rethrow;
    }
  }

  /// æ£€æŸ¥æä¾›å•†æ˜¯å¦æ”¯æŒTTS
  bool supportsTts(models.AiProvider provider) {
    switch (provider.type.name.toLowerCase()) {
      case 'openai':
      case 'elevenlabs':
        return true;
      default:
        return false;
    }
  }

  /// æ£€æŸ¥æä¾›å•†æ˜¯å¦æ”¯æŒSTT
  bool supportsStt(models.AiProvider provider) {
    switch (provider.type.name.toLowerCase()) {
      case 'openai':
        return true;
      default:
        return false;
    }
  }

  /// è·å–æ”¯æŒçš„è¯­éŸ³åˆ—è¡¨
  List<String> getSupportedVoices(models.AiProvider provider) {
    switch (provider.type.name.toLowerCase()) {
      case 'openai':
        return ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer'];
      case 'elevenlabs':
        return [
          'rachel',
          'domi',
          'bella',
          'antoni',
          'elli',
          'josh',
          'arnold',
          'adam',
          'sam',
        ];
      default:
        return [];
    }
  }

  /// æ¸…é™¤è¯­éŸ³ç¼“å­˜
  void clearCache([String? providerId]) {
    if (providerId != null) {
      final keysToRemove = [
        ..._ttsCache.keys.where((key) => key.startsWith('tts_${providerId}_')),
        ..._sttCache.keys.where((key) => key.startsWith('stt_${providerId}_')),
      ];

      for (final key in keysToRemove) {
        _ttsCache.remove(key);
        _sttCache.remove(key);
        _cacheTimestamps.remove(key);
      }

      logger.debug('æ¸…é™¤æä¾›å•†è¯­éŸ³ç¼“å­˜', {'provider': providerId});
    } else {
      _ttsCache.clear();
      _sttCache.clear();
      _cacheTimestamps.clear();
      logger.debug('æ¸…é™¤æ‰€æœ‰è¯­éŸ³ç¼“å­˜');
    }
  }

  /// è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
  Map<String, dynamic> getCacheStats() {
    return {
      'ttsCache': _ttsCache.length,
      'sttCache': _sttCache.length,
      'totalAudioSize': _ttsCache.values.fold<int>(
        0,
        (sum, audio) => sum + audio.length,
      ),
      'cacheTimestamps': _cacheTimestamps.map(
        (key, value) => MapEntry(key, value.toIso8601String()),
      ),
    };
  }

  /// æ£€æŸ¥TTSç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
  bool _isTtsCacheValid(String cacheKey) {
    return _ttsCache.containsKey(cacheKey) &&
        _cacheTimestamps.containsKey(cacheKey) &&
        DateTime.now().difference(_cacheTimestamps[cacheKey]!) < _cacheExpiry;
  }

  /// æ£€æŸ¥STTç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
  bool _isSttCacheValid(String cacheKey) {
    return _sttCache.containsKey(cacheKey) &&
        _cacheTimestamps.containsKey(cacheKey) &&
        DateTime.now().difference(_cacheTimestamps[cacheKey]!) < _cacheExpiry;
  }

  /// ç”ŸæˆTTSç¼“å­˜é”®
  String _generateTtsCacheKey(String providerId, String text, String? voice) {
    final textHash = text.hashCode.toString();
    final voiceHash = voice?.hashCode.toString() ?? 'default';
    return 'tts_${providerId}_${textHash}_$voiceHash';
  }

  /// ç”ŸæˆSTTç¼“å­˜é”®
  String _generateSttCacheKey(String providerId, Uint8List audioData) {
    final audioHash = audioData.hashCode.toString();
    return 'stt_${providerId}_$audioHash';
  }

  /// åˆ›å»ºä¸´æ—¶åŠ©æ‰‹
  AiAssistant _createTempAssistant() {
    return AiAssistant(
      id: 'temp-speech-assistant',
      name: 'Speech Assistant',
      avatar: 'ğŸ¤',
      systemPrompt: '',
      temperature: 0.0,
      topP: 1.0,
      maxTokens: 1,
      contextLength: 1,
      streamOutput: false,
      isEnabled: true,
      createdAt: DateTime.now(),
      updatedAt: DateTime.now(),
      description: 'ä¸´æ—¶è¯­éŸ³åŠ©æ‰‹',
      customHeaders: {},
      customBody: {},
      stopSequences: [],
      frequencyPenalty: 0.0,
      presencePenalty: 0.0,
      enableCodeExecution: false,
      enableImageGeneration: false,
      enableTools: false,
      enableReasoning: false,
      enableVision: false,
      enableEmbedding: false,
    );
  }

  /// è·å–TTSæ¨¡å‹
  String _getTtsModel(models.AiProvider provider) {
    switch (provider.type.name.toLowerCase()) {
      case 'openai':
        return 'tts-1';
      case 'elevenlabs':
        return 'eleven_multilingual_v2';
      default:
        return 'default-tts-model';
    }
  }

  /// è·å–STTæ¨¡å‹
  String _getSttModel(models.AiProvider provider) {
    switch (provider.type.name.toLowerCase()) {
      case 'openai':
        return 'whisper-1';
      default:
        return 'default-stt-model';
    }
  }
}
