import '../../../../features/chat/domain/entities/message.dart';
import '../../../../features/chat/domain/entities/message_block.dart';
import '../../../../features/chat/domain/entities/message_block_type.dart';
import '../../../../features/chat/domain/entities/message_block_status.dart';
import '../../../../features/chat/domain/entities/message_status.dart';
import '../../../../features/ai_management/domain/entities/ai_assistant.dart';
import '../../../../features/ai_management/domain/entities/ai_provider.dart' as models;
import '../media/media_storage_service.dart';
import 'ai_service_manager.dart';
import '../logger_service.dart';

/// åŸºäºå—çš„èŠå¤©æœåŠ¡ - ä½¿ç”¨æ–°çš„å—åŒ–æ¶ˆæ¯ç³»ç»Ÿçš„AIèŠå¤©æœåŠ¡
/// 
/// è¿™ä¸ªæœåŠ¡æ›¿ä»£äº†EnhancedChatServiceï¼Œä½¿ç”¨æ–°çš„å—åŒ–æ¶ˆæ¯æ¶æ„ï¼š
/// - ğŸ§© æ¶ˆæ¯å—åŒ–ç®¡ç† - æ¯ä¸ªæ¶ˆæ¯ç”±å¤šä¸ªå—ç»„æˆ
/// - ğŸ¨ å¤šåª’ä½“å—æ”¯æŒ - å›¾ç‰‡ã€éŸ³é¢‘ã€æ–‡ä»¶ç­‰ä½œä¸ºç‹¬ç«‹å—
/// - ğŸ”„ æµå¼å—æ›´æ–° - æ”¯æŒå®æ—¶å—çŠ¶æ€æ›´æ–°
/// - ğŸ“Š ç²¾ç»†åŒ–çŠ¶æ€ç®¡ç† - æ¯ä¸ªå—ç‹¬ç«‹çš„çŠ¶æ€è·Ÿè¸ª
/// 
/// ## æ ¸å¿ƒä¼˜åŠ¿
/// 
/// ### 1. æ›´å¥½çš„å†…å®¹ç»„ç»‡
/// - æ–‡æœ¬ã€å›¾ç‰‡ã€éŸ³é¢‘ç­‰å†…å®¹åˆ†ç¦»ç®¡ç†
/// - æ”¯æŒå¤æ‚çš„å¤šæ¨¡æ€æ¶ˆæ¯ç»“æ„
/// - ä¾¿äºå†…å®¹çš„ç‹¬ç«‹æ“ä½œå’Œå±•ç¤º
/// 
/// ### 2. å¢å¼ºçš„æµå¼ä½“éªŒ
/// - æ–‡æœ¬å—å¯ä»¥æµå¼æ›´æ–°
/// - å¤šåª’ä½“å—å¯ä»¥å¼‚æ­¥ç”Ÿæˆ
/// - ç”¨æˆ·å¯ä»¥çœ‹åˆ°æ¯ä¸ªå—çš„ç”Ÿæˆè¿›åº¦
/// 
/// ### 3. æ›´å¥½çš„é”™è¯¯å¤„ç†
/// - å•ä¸ªå—å¤±è´¥ä¸å½±å“æ•´ä¸ªæ¶ˆæ¯
/// - å¯ä»¥é‡è¯•å¤±è´¥çš„å—
/// - ç²¾ç¡®çš„é”™è¯¯å®šä½å’Œåé¦ˆ
class BlockBasedChatService {
  final AiServiceManager _serviceManager;
  final MediaStorageService _mediaService;
  final LoggerService _logger = LoggerService();

  // å›¾ç‰‡ç”Ÿæˆå…³é”®è¯æ£€æµ‹
  static const List<String> _imageGenerationKeywords = [
    'ç”»', 'ç»˜åˆ¶', 'ç”Ÿæˆå›¾ç‰‡', 'åˆ›å»ºå›¾åƒ', 'åˆ¶ä½œå›¾ç‰‡', 'è®¾è®¡å›¾ç‰‡',
    'ç”»ä¸€å¼ ', 'ç”»ä¸ª', 'ç”»å‡º', 'ç”Ÿæˆä¸€å¼ ', 'åˆ›ä½œå›¾ç‰‡', 'åˆ¶ä½œæµ·æŠ¥',
    'draw', 'paint', 'create image', 'generate image', 'make picture',
    'design', 'illustrate', 'sketch', 'render'
  ];

  // TTSç”Ÿæˆé˜ˆå€¼å’Œå…³é”®è¯
  static const int _ttsTextLengthThreshold = 100;
  static const List<String> _ttsRequestKeywords = [
    'è¯»å‡ºæ¥', 'æœ—è¯»', 'è¯­éŸ³æ’­æ”¾', 'å¿µç»™æˆ‘å¬', 'ç”¨è¯­éŸ³è¯´',
    'read aloud', 'speak', 'voice', 'audio', 'tts'
  ];

  BlockBasedChatService({
    required AiServiceManager serviceManager,
    required MediaStorageService mediaService,
  }) : _serviceManager = serviceManager,
       _mediaService = mediaService;

  /// å‘é€å—åŒ–èŠå¤©æ¶ˆæ¯ï¼ˆæ”¯æŒå¤šåª’ä½“ç”Ÿæˆï¼‰
  Future<Message> sendBlockMessage({
    required String conversationId,
    required models.AiProvider provider,
    required AiAssistant assistant,
    required String modelName,
    required List<Message> chatHistory,
    required String userMessage,
    bool autoGenerateImages = true,
    bool autoGenerateTts = true,
    bool enableImageAnalysis = true,
  }) async {
    final startTime = DateTime.now();
    final requestId = _generateRequestId();
    final messageId = _generateMessageId();

    _logger.info('å¼€å§‹å—åŒ–èŠå¤©è¯·æ±‚', {
      'requestId': requestId,
      'messageId': messageId,
      'provider': provider.name,
      'model': modelName,
      'autoGenerateImages': autoGenerateImages,
      'autoGenerateTts': autoGenerateTts,
    });

    try {
      // 1. æ£€æµ‹ç”¨æˆ·æ¶ˆæ¯ä¸­çš„å›¾ç‰‡ç”Ÿæˆè¯·æ±‚
      final shouldGenerateImage = autoGenerateImages && 
          _detectImageGenerationIntent(userMessage);

      // 2. å‘é€åŸºç¡€èŠå¤©è¯·æ±‚
      final chatResponse = await _serviceManager.sendMessage(
        provider: provider,
        assistant: assistant,
        modelName: modelName,
        chatHistory: chatHistory,
        userMessage: userMessage,
      );

      if (!chatResponse.isSuccess) {
        // å¦‚æœèŠå¤©å¤±è´¥ï¼Œè¿”å›é”™è¯¯æ¶ˆæ¯
        return Message(
          id: messageId,
          conversationId: conversationId,
          role: 'assistant',
          assistantId: assistant.id,
          status: MessageStatus.aiError,
          createdAt: DateTime.now(),
          updatedAt: DateTime.now(),
          blocks: [
            MessageBlock.error(
              id: '${messageId}_error',
              messageId: messageId,
              content: chatResponse.error ?? 'èŠå¤©è¯·æ±‚å¤±è´¥',
              error: {'originalError': chatResponse.error},
            ),
          ],
          metadata: {
            'modelName': modelName,
            'errorInfo': chatResponse.error,
          },
        );
      }

      final aiContent = chatResponse.content;
      final blocks = <MessageBlock>[];

      // 3. åˆ›å»ºä¸»æ–‡æœ¬å—
      blocks.add(MessageBlock.text(
        id: '${messageId}_text',
        messageId: messageId,
        content: aiContent,
        status: MessageBlockStatus.success,
        createdAt: DateTime.now(),
        modelId: assistant.id,
        modelName: modelName,
      ));

      // 4. å¤„ç†å›¾ç‰‡ç”Ÿæˆï¼ˆå¼‚æ­¥å—ï¼‰
      if (shouldGenerateImage) {
        final imageBlockId = '${messageId}_image';
        blocks.add(MessageBlock(
          id: imageBlockId,
          messageId: messageId,
          type: MessageBlockType.image,
          status: MessageBlockStatus.pending,
          createdAt: DateTime.now(),
          content: 'æ­£åœ¨ç”Ÿæˆå›¾ç‰‡...',
        ));

        // å¼‚æ­¥ç”Ÿæˆå›¾ç‰‡å¹¶æ›´æ–°å—
        _generateImageBlock(
          blockId: imageBlockId,
          messageId: messageId,
          provider: provider,
          aiResponse: aiContent,
          userPrompt: userMessage,
        ).then((imageBlock) {
          // è¿™é‡Œéœ€è¦é€šè¿‡æŸç§æœºåˆ¶æ›´æ–°æ¶ˆæ¯å—
          // å¯èƒ½éœ€è¦é€šè¿‡Repositoryæˆ–è€…äº‹ä»¶ç³»ç»Ÿ
          _logger.info('å›¾ç‰‡å—ç”Ÿæˆå®Œæˆ', {'blockId': imageBlockId});
        }).catchError((e) {
          _logger.warning('å›¾ç‰‡å—ç”Ÿæˆå¤±è´¥', {
            'blockId': imageBlockId,
            'error': e.toString(),
          });
        });
      }

      // 5. å¤„ç†TTSç”Ÿæˆï¼ˆå¼‚æ­¥å—ï¼‰
      if (autoGenerateTts && _shouldGenerateTts(aiContent, userMessage)) {
        final audioBlockId = '${messageId}_audio';
        blocks.add(MessageBlock(
          id: audioBlockId,
          messageId: messageId,
          type: MessageBlockType.file,
          status: MessageBlockStatus.pending,
          createdAt: DateTime.now(),
          content: 'æ­£åœ¨ç”Ÿæˆè¯­éŸ³...',
          metadata: {'fileType': 'audio', 'mimeType': 'audio/mpeg'},
        ));

        // å¼‚æ­¥ç”ŸæˆTTSå¹¶æ›´æ–°å—
        _generateTtsBlock(
          blockId: audioBlockId,
          messageId: messageId,
          provider: provider,
          text: aiContent,
        ).then((audioBlock) {
          _logger.info('TTSå—ç”Ÿæˆå®Œæˆ', {'blockId': audioBlockId});
        }).catchError((e) {
          _logger.warning('TTSå—ç”Ÿæˆå¤±è´¥', {
            'blockId': audioBlockId,
            'error': e.toString(),
          });
        });
      }

      // 6. åˆ›å»ºå—åŒ–æ¶ˆæ¯
      final blockMessage = Message(
        id: messageId,
        conversationId: conversationId,
        role: 'assistant',
        assistantId: assistant.id,
        status: MessageStatus.aiSuccess,
        createdAt: DateTime.now(),
        updatedAt: DateTime.now(),
        blocks: blocks,
        metadata: {
          'modelName': modelName,
          'totalDurationMs': DateTime.now().difference(startTime).inMilliseconds,
        },
      );

      _logger.info('å—åŒ–èŠå¤©è¯·æ±‚å®Œæˆ', {
        'requestId': requestId,
        'messageId': messageId,
        'duration': '${DateTime.now().difference(startTime).inMilliseconds}ms',
        'blocksCount': blocks.length,
        'textBlocks': blocks.where((b) => b.type == MessageBlockType.mainText).length,
        'imageBlocks': blocks.where((b) => b.type == MessageBlockType.image).length,
        'audioBlocks': blocks.where((b) => b.type == MessageBlockType.file && 
            b.metadata?['fileType'] == 'audio').length,
      });

      return blockMessage;

    } catch (e) {
      _logger.error('å—åŒ–èŠå¤©è¯·æ±‚å¤±è´¥', {
        'requestId': requestId,
        'messageId': messageId,
        'error': e.toString(),
      });

      return Message(
        id: messageId,
        conversationId: conversationId,
        role: 'assistant',
        assistantId: assistant.id,
        status: MessageStatus.aiError,
        createdAt: DateTime.now(),
        updatedAt: DateTime.now(),
        blocks: [
          MessageBlock.error(
            id: '${messageId}_error',
            messageId: messageId,
            content: 'æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é”™è¯¯ã€‚',
            error: {'exception': e.toString()},
          ),
        ],
        metadata: {
          'modelName': modelName,
          'errorInfo': e.toString(),
        },
      );
    }
  }

  /// æµå¼å‘é€å—åŒ–èŠå¤©æ¶ˆæ¯
  Stream<Message> sendBlockMessageStream({
    required String conversationId,
    required models.AiProvider provider,
    required AiAssistant assistant,
    required String modelName,
    required List<Message> chatHistory,
    required String userMessage,
    bool autoGenerateImages = true,
    bool autoGenerateTts = true,
  }) async* {
    final requestId = _generateRequestId();
    final messageId = _generateMessageId();
    final startTime = DateTime.now();

    _logger.info('å¼€å§‹å—åŒ–æµå¼èŠå¤©è¯·æ±‚', {
      'requestId': requestId,
      'messageId': messageId,
      'provider': provider.name,
      'model': modelName,
    });

    try {
      // æ£€æµ‹æ˜¯å¦éœ€è¦ç”Ÿæˆå›¾ç‰‡
      final shouldGenerateImage = autoGenerateImages && 
          _detectImageGenerationIntent(userMessage);

      var accumulatedContent = '';
      final blocks = <MessageBlock>[];
      
      // åˆ›å»ºåˆå§‹æ–‡æœ¬å—
      final textBlockId = '${messageId}_text';
      var textBlock = MessageBlock.text(
        id: textBlockId,
        messageId: messageId,
        content: '',
        status: MessageBlockStatus.streaming,
        createdAt: DateTime.now(),
        modelId: assistant.id,
        modelName: modelName,
      );
      blocks.add(textBlock);

      var currentMessage = Message(
        id: messageId,
        conversationId: conversationId,
        role: 'assistant',
        assistantId: assistant.id,
        status: MessageStatus.aiProcessing,
        createdAt: DateTime.now(),
        updatedAt: DateTime.now(),
        blocks: blocks,
        metadata: {
          'modelName': modelName,
        },
      );

      yield currentMessage;

      // å‘é€æµå¼èŠå¤©è¯·æ±‚
      await for (final event in _serviceManager.sendMessageStream(
        provider: provider,
        assistant: assistant,
        modelName: modelName,
        chatHistory: chatHistory,
        userMessage: userMessage,
      )) {
        if (event.isContent) {
          accumulatedContent += event.contentDelta ?? '';
          
          // æ›´æ–°æ–‡æœ¬å—
          textBlock = textBlock.copyWith(
            content: accumulatedContent,
            updatedAt: DateTime.now(),
          );
          
          // æ›´æ–°æ¶ˆæ¯
          currentMessage = currentMessage.copyWith(
            blocks: [textBlock, ...blocks.skip(1)],
            updatedAt: DateTime.now(),
          );
          
          yield currentMessage;
          
        } else if (event.isCompleted) {
          // æµå¼å®Œæˆï¼Œæ›´æ–°æ–‡æœ¬å—çŠ¶æ€
          textBlock = textBlock.copyWith(
            status: MessageBlockStatus.success,
            updatedAt: DateTime.now(),
          );
          
          final finalBlocks = [textBlock];

          // æ·»åŠ å¤šåª’ä½“å—ï¼ˆå¦‚æœéœ€è¦ï¼‰
          if (shouldGenerateImage) {
            finalBlocks.add(MessageBlock(
              id: '${messageId}_image',
              messageId: messageId,
              type: MessageBlockType.image,
              status: MessageBlockStatus.pending,
              createdAt: DateTime.now(),
              content: 'æ­£åœ¨ç”Ÿæˆå›¾ç‰‡...',
            ));
          }

          if (autoGenerateTts && _shouldGenerateTts(accumulatedContent, userMessage)) {
            finalBlocks.add(MessageBlock(
              id: '${messageId}_audio',
              messageId: messageId,
              type: MessageBlockType.file,
              status: MessageBlockStatus.pending,
              createdAt: DateTime.now(),
              content: 'æ­£åœ¨ç”Ÿæˆè¯­éŸ³...',
              metadata: {'fileType': 'audio', 'mimeType': 'audio/mpeg'},
            ));
          }

          // å‘é€æœ€ç»ˆæ¶ˆæ¯
          currentMessage = currentMessage.copyWith(
            status: MessageStatus.aiSuccess,
            blocks: finalBlocks,
            updatedAt: DateTime.now(),
            metadata: {
              ...?currentMessage.metadata,
              'totalDurationMs': DateTime.now().difference(startTime).inMilliseconds,
            },
          );

          yield currentMessage;
          
        } else if (event.isError) {
          // æ›´æ–°ä¸ºé”™è¯¯çŠ¶æ€
          textBlock = textBlock.copyWith(
            status: MessageBlockStatus.error,
            error: {'streamError': event.error},
            updatedAt: DateTime.now(),
          );
          
          currentMessage = currentMessage.copyWith(
            status: MessageStatus.aiError,
            blocks: [textBlock],
            updatedAt: DateTime.now(),
            metadata: {
              ...?currentMessage.metadata,
              'errorInfo': event.error,
            },
          );
          
          yield currentMessage;
        }
      }

    } catch (e) {
      _logger.error('å—åŒ–æµå¼èŠå¤©è¯·æ±‚å¤±è´¥', {
        'requestId': requestId,
        'messageId': messageId,
        'error': e.toString(),
      });

      yield Message(
        id: messageId,
        conversationId: conversationId,
        role: 'assistant',
        assistantId: assistant.id,
        status: MessageStatus.aiError,
        createdAt: DateTime.now(),
        updatedAt: DateTime.now(),
        blocks: [
          MessageBlock.error(
            id: '${messageId}_error',
            messageId: messageId,
            content: 'æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é”™è¯¯ã€‚',
            error: {'exception': e.toString()},
          ),
        ],
        metadata: {
          'modelName': modelName,
          'errorInfo': e.toString(),
        },
      );
    }
  }

  // ç§æœ‰è¾…åŠ©æ–¹æ³•

  /// æ£€æµ‹ç”¨æˆ·æ¶ˆæ¯ä¸­çš„å›¾ç‰‡ç”Ÿæˆæ„å›¾
  bool _detectImageGenerationIntent(String userMessage) {
    final lowerMessage = userMessage.toLowerCase();
    return _imageGenerationKeywords.any((keyword) =>
        lowerMessage.contains(keyword.toLowerCase()));
  }

  /// åˆ¤æ–­æ˜¯å¦åº”è¯¥ç”ŸæˆTTS
  bool _shouldGenerateTts(String aiResponse, String userMessage) {
    // 1. ç”¨æˆ·æ˜ç¡®è¯·æ±‚è¯­éŸ³
    final lowerUserMessage = userMessage.toLowerCase();
    if (_ttsRequestKeywords.any((keyword) =>
        lowerUserMessage.contains(keyword.toLowerCase()))) {
      return true;
    }

    // 2. AIå›å¤æ–‡æœ¬è¾ƒé•¿
    if (aiResponse.length > _ttsTextLengthThreshold) {
      return true;
    }

    // 3. å›å¤åŒ…å«è¯—æ­Œã€æ•…äº‹ç­‰é€‚åˆæœ—è¯»çš„å†…å®¹
    final lowerResponse = aiResponse.toLowerCase();
    final narrativeKeywords = ['æ•…äº‹', 'è¯—æ­Œ', 'è¯—', 'ç«¥è¯', 'å°è¯´', 'story', 'poem', 'tale'];
    if (narrativeKeywords.any((keyword) =>
        lowerResponse.contains(keyword.toLowerCase()))) {
      return true;
    }

    return false;
  }

  /// å¼‚æ­¥ç”Ÿæˆå›¾ç‰‡å—
  Future<MessageBlock> _generateImageBlock({
    required String blockId,
    required String messageId,
    required models.AiProvider provider,
    required String aiResponse,
    required String userPrompt,
  }) async {
    try {
      // æ£€æŸ¥æä¾›å•†æ˜¯å¦æ”¯æŒå›¾ç‰‡ç”Ÿæˆ
      final imageService = _serviceManager.imageGenerationService;
      if (!imageService.supportsImageGeneration(provider)) {
        return MessageBlock.error(
          id: blockId,
          messageId: messageId,
          content: 'å½“å‰æä¾›å•†ä¸æ”¯æŒå›¾ç‰‡ç”Ÿæˆ',
          error: {'reason': 'provider_not_supported'},
        );
      }

      // æå–æˆ–ç”Ÿæˆå›¾ç‰‡æè¿°
      final imagePrompt = _extractImagePrompt(userPrompt, aiResponse);
      if (imagePrompt.isEmpty) {
        return MessageBlock.error(
          id: blockId,
          messageId: messageId,
          content: 'æ— æ³•æå–å›¾ç‰‡æè¿°',
          error: {'reason': 'no_image_prompt'},
        );
      }

      // ç”Ÿæˆå›¾ç‰‡
      final imageResponse = await imageService.generateImage(
        provider: provider,
        prompt: imagePrompt,
        size: '1024x1024',
        quality: 'standard',
        count: 1,
      );

      if (!imageResponse.isSuccess || imageResponse.images.isEmpty) {
        return MessageBlock.error(
          id: blockId,
          messageId: messageId,
          content: 'å›¾ç‰‡ç”Ÿæˆå¤±è´¥: ${imageResponse.error}',
          error: {'reason': 'generation_failed', 'details': imageResponse.error},
        );
      }

      final generatedImage = imageResponse.images.first;

      // åˆ›å»ºæˆåŠŸçš„å›¾ç‰‡å—
      return MessageBlock.image(
        id: blockId,
        messageId: messageId,
        url: generatedImage.url!,
        status: MessageBlockStatus.success,
        createdAt: DateTime.now(),
      );

    } catch (e) {
      return MessageBlock.error(
        id: blockId,
        messageId: messageId,
        content: 'å›¾ç‰‡ç”Ÿæˆå¼‚å¸¸: $e',
        error: {'reason': 'exception', 'details': e.toString()},
      );
    }
  }

  /// å¼‚æ­¥ç”ŸæˆTTSå—
  Future<MessageBlock> _generateTtsBlock({
    required String blockId,
    required String messageId,
    required models.AiProvider provider,
    required String text,
  }) async {
    try {
      // æ£€æŸ¥æä¾›å•†æ˜¯å¦æ”¯æŒTTS
      final speechService = _serviceManager.speechService;
      if (!speechService.supportsTts(provider)) {
        return MessageBlock.error(
          id: blockId,
          messageId: messageId,
          content: 'å½“å‰æä¾›å•†ä¸æ”¯æŒè¯­éŸ³åˆæˆ',
          error: {'reason': 'provider_not_supported'},
        );
      }

      // ç”ŸæˆTTS
      final audioData = await speechService.textToSpeech(
        provider: provider,
        text: text,
        voice: null, // ä½¿ç”¨é»˜è®¤è¯­éŸ³
      );

      // å­˜å‚¨éŸ³é¢‘æ–‡ä»¶
      final audioMetadata = await _mediaService.storeMedia(
        data: audioData,
        fileName: 'tts_${DateTime.now().millisecondsSinceEpoch}.mp3',
        mimeType: 'audio/mpeg',
        customProperties: {
          'type': 'tts',
          'provider': provider.name,
          'text_length': text.length,
        },
      );

      // åˆ›å»ºæˆåŠŸçš„éŸ³é¢‘å—
      return MessageBlock(
        id: blockId,
        messageId: messageId,
        type: MessageBlockType.file,
        status: MessageBlockStatus.success,
        createdAt: DateTime.now(),
        url: audioMetadata.networkUrl ?? audioMetadata.localPath,
        fileId: audioMetadata.id,
        metadata: {
          'fileName': audioMetadata.fileName,
          'mimeType': audioMetadata.mimeType,
          'sizeBytes': audioMetadata.sizeBytes,
          'fileType': 'audio',
        },
      );

    } catch (e) {
      return MessageBlock.error(
        id: blockId,
        messageId: messageId,
        content: 'TTSç”Ÿæˆå¼‚å¸¸: $e',
        error: {'reason': 'exception', 'details': e.toString()},
      );
    }
  }

  /// æå–å›¾ç‰‡æç¤ºè¯
  String _extractImagePrompt(String userPrompt, String aiResponse) {
    // ç®€å•çš„æç¤ºè¯æå–é€»è¾‘
    // åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œå¯èƒ½éœ€è¦æ›´å¤æ‚çš„NLPå¤„ç†
    final lowerUserPrompt = userPrompt.toLowerCase();
    
    // å¦‚æœç”¨æˆ·æ¶ˆæ¯åŒ…å«å›¾ç‰‡ç”Ÿæˆå…³é”®è¯ï¼Œä½¿ç”¨ç”¨æˆ·æ¶ˆæ¯
    if (_imageGenerationKeywords.any((keyword) =>
        lowerUserPrompt.contains(keyword.toLowerCase()))) {
      return userPrompt;
    }
    
    // å¦åˆ™å°è¯•ä»AIå›å¤ä¸­æå–æè¿°
    if (aiResponse.length > 50) {
      return aiResponse.substring(0, 200); // å–å‰200å­—ç¬¦ä½œä¸ºæç¤ºè¯
    }
    
    return userPrompt;
  }

  /// ç”Ÿæˆè¯·æ±‚ID
  String _generateRequestId() {
    return 'req_${DateTime.now().millisecondsSinceEpoch}_${DateTime.now().microsecond}';
  }

  /// ç”Ÿæˆæ¶ˆæ¯ID
  String _generateMessageId() {
    return 'msg_${DateTime.now().millisecondsSinceEpoch}_${DateTime.now().microsecond}';
  }
}
