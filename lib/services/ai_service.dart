import 'package:langchain_openai/langchain_openai.dart';
import 'package:langchain/langchain.dart';
import 'dart:async';
import '../models/ai_provider.dart';
import '../models/ai_assistant.dart';
import '../models/ai_model.dart';
import '../models/message.dart';
import 'notification_service.dart';
import 'logger_service.dart';
import 'provider_repository.dart';
import 'assistant_repository.dart';
import 'database_service.dart';

// è°ƒè¯•ä¿¡æ¯ç±»
class DebugInfo {
  final String assistantId;
  final String providerId;
  final String modelName;
  final Map<String, dynamic> requestBody;
  final int? statusCode;
  final String? response;
  final String? error;
  final DateTime timestamp;
  final Duration? duration;
  final bool wasStopped;

  DebugInfo({
    required this.assistantId,
    required this.providerId,
    required this.modelName,
    required this.requestBody,
    this.statusCode,
    this.response,
    this.error,
    required this.timestamp,
    this.duration,
    this.wasStopped = false,
  });
}

// AIé”™è¯¯ç±»å‹
enum AiErrorType {
  invalidApiKey,
  networkError,
  modelNotFound,
  rateLimitExceeded,
  insufficientQuota,
  serverError,
  configError,
  timeout,
  cancelled,
  unknown,
}

// AIé”™è¯¯ä¿¡æ¯
class AiError {
  final AiErrorType type;
  final String message;
  final String? technicalDetails;
  final String? suggestion;

  const AiError({
    required this.type,
    required this.message,
    this.technicalDetails,
    this.suggestion,
  });

  static AiError fromException(dynamic error) {
    final errorMessage = error.toString().toLowerCase();

    // æ£€æŸ¥å–æ¶ˆé”™è¯¯
    if (errorMessage.contains('cancelled') ||
        errorMessage.contains('operation cancelled')) {
      return AiError(
        type: AiErrorType.cancelled,
        message: 'è¯·æ±‚å·²è¢«å–æ¶ˆ',
        technicalDetails: error.toString(),
        suggestion: 'ç”¨æˆ·ä¸»åŠ¨åœæ­¢äº†ç”Ÿæˆ',
      );
    }

    // æ£€æŸ¥è¶…æ—¶é”™è¯¯
    if (errorMessage.contains('timeout') ||
        errorMessage.contains('timed out')) {
      return AiError(
        type: AiErrorType.timeout,
        message: 'è¯·æ±‚è¶…æ—¶',
        technicalDetails: error.toString(),
        suggestion: 'ç½‘ç»œå¯èƒ½è¾ƒæ…¢ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•',
      );
    }

    if (errorMessage.contains('unauthorized') ||
        errorMessage.contains('invalid api key') ||
        errorMessage.contains('incorrect api key')) {
      return AiError(
        type: AiErrorType.invalidApiKey,
        message: 'APIå¯†é’¥æ— æ•ˆ',
        technicalDetails: error.toString(),
        suggestion: 'è¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å‰å¾€è®¾ç½®é¡µé¢é‡æ–°é…ç½®',
      );
    }

    if (errorMessage.contains('rate limit') ||
        errorMessage.contains('too many requests')) {
      return AiError(
        type: AiErrorType.rateLimitExceeded,
        message: 'è¯·æ±‚è¿‡äºé¢‘ç¹',
        technicalDetails: error.toString(),
        suggestion: 'è¯·ç¨ç­‰ç‰‡åˆ»åå†è¯•',
      );
    }

    if (errorMessage.contains('insufficient_quota') ||
        errorMessage.contains('quota exceeded')) {
      return AiError(
        type: AiErrorType.insufficientQuota,
        message: 'è´¦æˆ·ä½™é¢ä¸è¶³',
        technicalDetails: error.toString(),
        suggestion: 'è¯·æ£€æŸ¥è´¦æˆ·ä½™é¢æˆ–å‡çº§è®¢é˜…è®¡åˆ’',
      );
    }

    if (errorMessage.contains('model') && errorMessage.contains('not found')) {
      return AiError(
        type: AiErrorType.modelNotFound,
        message: 'æ¨¡å‹ä¸å­˜åœ¨',
        technicalDetails: error.toString(),
        suggestion: 'è¯·æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®ï¼Œæˆ–é€‰æ‹©å…¶ä»–å¯ç”¨æ¨¡å‹',
      );
    }

    if (errorMessage.contains('network') ||
        errorMessage.contains('connection') ||
        errorMessage.contains('socket')) {
      return AiError(
        type: AiErrorType.networkError,
        message: 'ç½‘ç»œè¿æ¥å¤±è´¥',
        technicalDetails: error.toString(),
        suggestion: 'è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸',
      );
    }

    if (errorMessage.contains('server error') ||
        errorMessage.contains('internal error') ||
        errorMessage.contains('500')) {
      return AiError(
        type: AiErrorType.serverError,
        message: 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯',
        technicalDetails: error.toString(),
        suggestion: 'æœåŠ¡å™¨ä¸´æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•',
      );
    }

    return AiError(
      type: AiErrorType.unknown,
      message: 'æœªçŸ¥é”™è¯¯',
      technicalDetails: error.toString(),
      suggestion: 'è¯·å°è¯•é‡æ–°å‘é€æ¶ˆæ¯ï¼Œæˆ–è”ç³»æŠ€æœ¯æ”¯æŒ',
    );
  }
}

class AiService {
  static final AiService _instance = AiService._internal();
  factory AiService() => _instance;
  AiService._internal();

  // Loggerå®ä¾‹
  final LoggerService _logger = LoggerService();

  // å†…å­˜å­˜å‚¨
  final Map<String, AiProvider> _providers = {};
  final Map<String, AiAssistant> _assistants = {};
  final Map<String, ChatOpenAI> _clients = {}; // ç¼“å­˜å®¢æˆ·ç«¯

  // æµå¼è¯·æ±‚æ§åˆ¶å™¨æ˜ å°„
  final Map<String, StreamController<String>> _streamControllers = {};
  final Map<String, StreamSubscription> _streamSubscriptions = {};

  // è°ƒè¯•ä¿¡æ¯å­˜å‚¨
  final List<DebugInfo> _debugLogs = [];
  bool _debugMode = true; // é»˜è®¤å¼€å¯è°ƒè¯•æ¨¡å¼

  // è·å–è°ƒè¯•æ—¥å¿—
  List<DebugInfo> get debugLogs => List.unmodifiable(_debugLogs);
  bool get debugMode => _debugMode;

  void setDebugMode(bool enabled) {
    _debugMode = enabled;
    _logger.info('è°ƒè¯•æ¨¡å¼${enabled ? 'å¼€å¯' : 'å…³é—­'}');
  }

  void clearDebugLogs() {
    _debugLogs.clear();
    _logger.info('è°ƒè¯•æ—¥å¿—å·²æ¸…ç©º');
  }

  // æ£€æŸ¥æ˜¯å¦æ­£åœ¨ç”Ÿæˆ
  bool isGenerating(String requestId) {
    return _streamControllers.containsKey(requestId);
  }

  // åœæ­¢ç”Ÿæˆ
  void stopGeneration(String requestId) {
    final controller = _streamControllers[requestId];
    final subscription = _streamSubscriptions[requestId];

    if (controller != null || subscription != null) {
      _logger.warning('åœæ­¢AIç”Ÿæˆ', requestId);

      subscription?.cancel();
      controller?.close();

      _streamControllers.remove(requestId);
      _streamSubscriptions.remove(requestId);

      NotificationService().showInfo('å·²åœæ­¢ç”Ÿæˆ');
    }
  }

  // æ·»åŠ è°ƒè¯•æ—¥å¿—
  void _addDebugLog(DebugInfo debug) {
    if (_debugMode) {
      _debugLogs.add(debug);
      // ä¿æŒæœ€è¿‘100æ¡è®°å½•
      if (_debugLogs.length > 100) {
        _debugLogs.removeAt(0);
      }
    }
  }

  // åˆå§‹åŒ–é»˜è®¤æ•°æ®
  Future<void> initialize() async {
    final providerRepository = ProviderRepository(
      DatabaseService.instance.database,
    );
    final assistantRepository = AssistantRepository(
      DatabaseService.instance.database,
    );
    _logger.info('åˆå§‹åŒ–AIæœåŠ¡');

    // å¤„ç†é»˜è®¤æä¾›å•†
    final allDbProviders = await providerRepository.getAllProviders();
    for (final p in allDbProviders) {
      _providers[p.id] = p;
    }

    const defaultProviderId = 'openai-default';
    if (!_providers.containsKey(defaultProviderId)) {
      final defaultOpenAiProvider = AiProvider(
        id: defaultProviderId,
        name: 'OpenAI (é»˜è®¤)',
        type: ProviderType.openai,
        apiKey: 'sk-', // ç”¨æˆ·éœ€è¦æ›¿æ¢
        baseUrl: 'https://api.openai.com/v1',
        models: [
          AiModel(
            id: 'gpt-3.5-turbo',
            name: 'gpt-3.5-turbo',
            displayName: 'GPT-3.5 Turbo',
            createdAt: DateTime.now(),
            updatedAt: DateTime.now(),
          ),
        ],
        createdAt: DateTime.now(),
        updatedAt: DateTime.now(),
        isEnabled: true,
      );
      _providers[defaultOpenAiProvider.id] = defaultOpenAiProvider;
      await providerRepository.insertProvider(defaultOpenAiProvider);
      _logger.info('å·²åˆ›å»ºå¹¶ä¿å­˜é»˜è®¤OpenAIæä¾›å•†: ${defaultOpenAiProvider.name}');
    }

    // å¤„ç†é»˜è®¤åŠ©æ‰‹
    final allDbAssistants = await assistantRepository.getAllAssistants();
    for (final a in allDbAssistants) {
      _assistants[a.id] = a;
    }

    const defaultAssistantId = 'default-assistant';
    if (!_assistants.containsKey(defaultAssistantId)) {
      if (_providers.containsKey('openai-default')) {
        final defaultAssistant = AiAssistant(
          id: defaultAssistantId,
          name: 'é»˜è®¤åŠ©æ‰‹',
          avatar: 'ğŸ¤–',
          systemPrompt: 'ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ã€‚',
          providerId: 'openai-default', // å…³è”é»˜è®¤æä¾›å•†
          modelName: 'gpt-3.5-turbo', // é»˜è®¤æ¨¡å‹
          temperature: 0.7,
          topP: 1.0,
          maxTokens: 4096,
          contextLength: 32,
          streamOutput: true,
          isEnabled: true,
          createdAt: DateTime.now(),
          updatedAt: DateTime.now(),
          description: '',
          customHeaders: {},
          customBody: {},
          stopSequences: [],
          frequencyPenalty: 0.0,
          presencePenalty: 0.0,
          enableWebSearch: false,
          enableCodeExecution: false,
          enableImageGeneration: false,
        );
        _assistants[defaultAssistant.id] = defaultAssistant;
        await assistantRepository.insertAssistant(defaultAssistant);
        _logger.info('å·²åˆ›å»ºå¹¶ä¿å­˜é»˜è®¤åŠ©æ‰‹: ${defaultAssistant.name}');
      } else {
        _logger.warning('æ— æ³•åˆ›å»ºé»˜è®¤åŠ©æ‰‹ï¼Œå› ä¸ºé»˜è®¤OpenAIæä¾›å•†ä¸å­˜åœ¨ã€‚');
      }
    }
  }

  // === æä¾›å•†ç®¡ç† ===

  List<AiProvider> get providers => _providers.values.toList();

  AiProvider? getProvider(String id) => _providers[id];

  void addProvider(AiProvider provider) {
    _providers[provider.id] = provider;
    // æ¸…é™¤ç›¸å…³å®¢æˆ·ç«¯ç¼“å­˜
    _clients.remove(provider.id);
    _logger.info('æ·»åŠ AIæä¾›å•†: ${provider.name} (${provider.type.name})');
  }

  void updateProvider(AiProvider provider) {
    _providers[provider.id] = provider;
    // æ¸…é™¤ç›¸å…³å®¢æˆ·ç«¯ç¼“å­˜
    _clients.remove(provider.id);
    _logger.info('æ›´æ–°AIæä¾›å•†: ${provider.name}');
  }

  void removeProvider(String id) {
    final provider = _providers[id];
    _providers.remove(id);
    _clients.remove(id);
    // ç§»é™¤ç›¸å…³åŠ©æ‰‹
    _assistants.removeWhere((_, assistant) => assistant.providerId == id);
    _logger.info('åˆ é™¤AIæä¾›å•†: ${provider?.name ?? id}');
  }

  // === åŠ©æ‰‹ç®¡ç† ===

  List<AiAssistant> get assistants => _assistants.values.toList();

  AiAssistant? getAssistant(String id) => _assistants[id];

  void addAssistant(AiAssistant assistant) {
    _assistants[assistant.id] = assistant;
    _logger.info('æ·»åŠ AIåŠ©æ‰‹: ${assistant.name}');
  }

  void updateAssistant(AiAssistant assistant) {
    _assistants[assistant.id] = assistant;
    _logger.info('æ›´æ–°AIåŠ©æ‰‹: ${assistant.name}');
  }

  void removeAssistant(String id) {
    final assistant = _assistants[id];
    _assistants.remove(id);
    _logger.info('åˆ é™¤AIåŠ©æ‰‹: ${assistant?.name ?? id}');
  }

  // æ ¹æ®æä¾›å•†è·å–åŠ©æ‰‹
  List<AiAssistant> getAssistantsByProvider(String providerId) {
    return _assistants.values
        .where((assistant) => assistant.providerId == providerId)
        .toList();
  }

  // === èŠå¤©åŠŸèƒ½ ===

  // è·å–æˆ–åˆ›å»ºChatOpenAIå®¢æˆ·ç«¯
  ChatOpenAI? _getClient(String providerId) {
    if (_clients.containsKey(providerId)) {
      return _clients[providerId];
    }

    final provider = _providers[providerId];
    if (provider == null || !provider.isEnabled) {
      _logger.warning('æä¾›å•†ä¸å¯ç”¨: $providerId');
      return null;
    }

    // éªŒè¯APIå¯†é’¥æ ¼å¼
    if (!_isValidApiKey(provider)) {
      _logger.error('APIå¯†é’¥æ ¼å¼æ— æ•ˆ: ${provider.name}');
      NotificationService().showError(
        'APIå¯†é’¥æ ¼å¼æ— æ•ˆ',
        actionLabel: 'æŸ¥çœ‹è¦æ±‚',
        onActionPressed: () {
          NotificationService().showInfo(_getApiKeyRequirement(provider.type));
        },
      );
      return null;
    }

    ChatOpenAI client;

    try {
      switch (provider.type) {
        case ProviderType.openai:
        case ProviderType.custom:
          client = ChatOpenAI(
            apiKey: provider.apiKey,
            baseUrl: provider.baseUrl ?? 'https://api.openai.com/v1',
            defaultOptions: ChatOpenAIOptions(
              model: 'gpt-3.5-turbo', // é»˜è®¤æ¨¡å‹ï¼Œä¼šè¢«è¯·æ±‚æ—¶è¦†ç›–
              temperature: 0.7,
            ),
          );
          break;

        case ProviderType.ollama:
          client = ChatOpenAI(
            apiKey: 'ollama', // Ollamaä¸éœ€è¦çœŸå®çš„API key
            baseUrl: provider.effectiveBaseUrl,
            defaultOptions: ChatOpenAIOptions(
              model: 'llama2', // é»˜è®¤æ¨¡å‹
              temperature: 0.7,
            ),
          );
          break;

        default:
          // å…¶ä»–æä¾›å•†æš‚ä¸æ”¯æŒï¼Œåç»­å¯æ‰©å±•
          _logger.warning('ä¸æ”¯æŒçš„æä¾›å•†ç±»å‹: ${provider.type}');
          return null;
      }

      _clients[providerId] = client;
      _logger.info('åˆ›å»ºAIå®¢æˆ·ç«¯: ${provider.name} -> ${provider.effectiveBaseUrl}');
      return client;
    } catch (e) {
      _logger.error('åˆ›å»ºå®¢æˆ·ç«¯å¤±è´¥', e);
      return null;
    }
  }

  // éªŒè¯APIå¯†é’¥æ ¼å¼
  bool _isValidApiKey(AiProvider provider) {
    switch (provider.type) {
      case ProviderType.openai:
      case ProviderType.custom:
        // OpenAI APIå¯†é’¥åº”è¯¥ä»¥sk-å¼€å¤´
        return provider.apiKey.isNotEmpty &&
            (provider.apiKey.startsWith('sk-') ||
                provider.apiKey == 'sk-test-example-key'); // å…è®¸ç¤ºä¾‹å¯†é’¥
      case ProviderType.ollama:
        // Ollamaä¸éœ€è¦çœŸå®çš„APIå¯†é’¥
        return true;
      default:
        return provider.apiKey.isNotEmpty;
    }
  }

  // è·å–APIå¯†é’¥è¦æ±‚è¯´æ˜
  String _getApiKeyRequirement(ProviderType type) {
    switch (type) {
      case ProviderType.openai:
        return 'OpenAI APIå¯†é’¥åº”è¯¥ä»¥"sk-"å¼€å¤´ï¼Œä¾‹å¦‚ï¼šsk-xxxxxxxxxxxxxxxx...';
      case ProviderType.anthropic:
        return 'Anthropic APIå¯†é’¥åº”è¯¥ä»¥"sk-ant-"å¼€å¤´';
      case ProviderType.google:
        return 'Google AI APIå¯†é’¥æ ¼å¼è¯·å‚è€ƒå®˜æ–¹æ–‡æ¡£';
      case ProviderType.ollama:
        return 'Ollamaè¿è¡Œåœ¨æœ¬åœ°ï¼Œä¸éœ€è¦APIå¯†é’¥';
      case ProviderType.custom:
        return 'è¯·æ ¹æ®å…·ä½“APIæä¾›å•†çš„è¦æ±‚è¾“å…¥æ­£ç¡®æ ¼å¼çš„APIå¯†é’¥';
    }
  }

  // è·å–æ¶ˆæ¯è§’è‰²ï¼ˆç”¨äºè°ƒè¯•ï¼‰
  String _getMessageRole(ChatMessage message) {
    if (message is SystemChatMessage) return 'system';
    if (message is HumanChatMessage) return 'user';
    if (message is AIChatMessage) return 'assistant';
    return 'unknown';
  }

  // è·å–æ¶ˆæ¯å†…å®¹ï¼ˆç”¨äºè°ƒè¯•ï¼‰
  String _getMessageContent(ChatMessage message) {
    // ç®€åŒ–å¤„ç†ï¼Œç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç”¨äºè°ƒè¯•
    return message.toString();
  }

  // å‘é€èŠå¤©æ¶ˆæ¯
  Future<String?> sendMessage({
    required String assistantId,
    required List<Message> chatHistory,
    required String userMessage,
    required String selectedProviderId,
    required String selectedModelName,
  }) async {
    final startTime = DateTime.now();
    final requestId = '${assistantId}_${startTime.millisecondsSinceEpoch}';

    _logger.info('å¼€å§‹å‘é€AIæ¶ˆæ¯', {
      'assistantId': assistantId,
      'selectedProviderId': selectedProviderId,
      'selectedModelName': selectedModelName,
      'requestId': requestId,
    });

    final assistant = _assistants[assistantId];
    if (assistant == null) {
      const error = 'æ‰¾ä¸åˆ°æŒ‡å®šçš„åŠ©æ‰‹é…ç½®';
      _logger.error('åŠ©æ‰‹ä¸å­˜åœ¨', {'assistantId': assistantId});
      _addDebugLog(
        DebugInfo(
          assistantId: assistantId,
          providerId: selectedProviderId,
          modelName: selectedModelName,
          requestBody: {'error': 'assistant_not_found'},
          error: error,
          timestamp: startTime,
        ),
      );
      NotificationService().showError(error);
      return null;
    }

    final provider = _providers[selectedProviderId];
    if (provider == null) {
      const error = 'æ‰¾ä¸åˆ°æŒ‡å®šçš„AIæä¾›å•†é…ç½®';
      _logger.error('æä¾›å•†ä¸å­˜åœ¨', {'providerId': selectedProviderId});
      _addDebugLog(
        DebugInfo(
          assistantId: assistantId,
          providerId: selectedProviderId,
          modelName: selectedModelName,
          requestBody: {'error': 'provider_not_found'},
          error: error,
          timestamp: startTime,
        ),
      );
      NotificationService().showError(error);
      return null;
    }

    if (!provider.isEnabled) {
      const error = 'AIæä¾›å•†æœªå¯ç”¨ï¼Œè¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½®';
      _logger.warning('æä¾›å•†æœªå¯ç”¨', {'providerId': selectedProviderId});
      _addDebugLog(
        DebugInfo(
          assistantId: assistantId,
          providerId: selectedProviderId,
          modelName: selectedModelName,
          requestBody: {'error': 'provider_disabled'},
          error: error,
          timestamp: startTime,
        ),
      );
      NotificationService().showError(error);
      return null;
    }

    final client = _getClient(selectedProviderId);
    if (client == null) {
      const error = 'æ— æ³•åˆ›å»ºAIå®¢æˆ·ç«¯ï¼Œè¯·æ£€æŸ¥é…ç½®';
      _logger.error('å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥', {'providerId': selectedProviderId});
      _addDebugLog(
        DebugInfo(
          assistantId: assistantId,
          providerId: selectedProviderId,
          modelName: selectedModelName,
          requestBody: {'error': 'client_creation_failed'},
          error: error,
          timestamp: startTime,
        ),
      );
      NotificationService().showError(error);
      return null;
    }

    try {
      // æ„å»ºæ¶ˆæ¯åˆ—è¡¨
      final messages = _buildChatMessages(assistant, chatHistory, userMessage);

      // æ„å»ºè¯·æ±‚ä½“ç”¨äºè°ƒè¯•
      final requestBody = {
        'model': selectedModelName,
        'messages': messages
            .map(
              (m) => {
                'role': _getMessageRole(m),
                'content': _getMessageContent(m),
              },
            )
            .toList(),
        'temperature': assistant.temperature,
        'top_p': assistant.topP,
        'max_tokens': assistant.maxTokens,
      };

      _logger.aiRequest(assistantId, selectedModelName, requestBody);

      // è®¾ç½®æ¨¡å‹å‚æ•°å¹¶å‘é€è¯·æ±‚
      final modelClient = client.bind(
        ChatOpenAIOptions(
          model: selectedModelName,
          temperature: assistant.temperature,
          topP: assistant.topP,
          maxTokens: assistant.maxTokens,
        ),
      );

      // æ·»åŠ è¶…æ—¶å¤„ç†
      final response = await modelClient
          .invoke(PromptValue.chat(messages))
          .timeout(const Duration(seconds: 15)); // 15ç§’è¶…æ—¶

      final duration = DateTime.now().difference(startTime);
      final responseContent = response.output.content;

      _logger.aiResponse(assistantId, responseContent, duration);

      _addDebugLog(
        DebugInfo(
          assistantId: assistantId,
          providerId: selectedProviderId,
          modelName: selectedModelName,
          requestBody: requestBody,
          statusCode: 200,
          response: responseContent,
          timestamp: startTime,
          duration: duration,
        ),
      );

      return responseContent;
    } catch (e) {
      final duration = DateTime.now().difference(startTime);
      final aiError = AiError.fromException(e);

      _logger.aiError(
        assistantId,
        aiError.technicalDetails ?? 'unknown error',
        duration,
      );

      _addDebugLog(
        DebugInfo(
          assistantId: assistantId,
          providerId: selectedProviderId,
          modelName: selectedModelName,
          requestBody: {
            'model': selectedModelName,
            'temperature': assistant.temperature,
            'top_p': assistant.topP,
            'user_message': userMessage,
          },
          error: aiError.technicalDetails,
          timestamp: startTime,
          duration: duration,
        ),
      );

      // æ˜¾ç¤ºç”¨æˆ·å‹å¥½çš„é”™è¯¯é€šçŸ¥
      NotificationService().showError(
        aiError.message,
        actionLabel: aiError.suggestion != null ? 'æŸ¥çœ‹å»ºè®®' : null,
        onActionPressed: aiError.suggestion != null
            ? () {
                NotificationService().showInfo(aiError.suggestion!);
              }
            : null,
      );

      // è¿”å›é”™è¯¯ä¿¡æ¯ï¼Œä¾›èŠå¤©ç•Œé¢æ˜¾ç¤ºåœ¨æ°”æ³¡ä¸­
      return '[é”™è¯¯] ${aiError.message}${aiError.suggestion != null ? "\nğŸ’¡ ${aiError.suggestion}" : ""}';
    }
  }

  // å‘é€æµå¼èŠå¤©æ¶ˆæ¯
  Stream<String> sendMessageStream({
    required String assistantId,
    required List<Message> chatHistory,
    required String userMessage,
    required String selectedProviderId,
    required String selectedModelName,
  }) async* {
    final startTime = DateTime.now();
    final requestId = '${assistantId}_${startTime.millisecondsSinceEpoch}';

    _logger.info('å¼€å§‹å‘é€AIæµå¼æ¶ˆæ¯', {
      'assistantId': assistantId,
      'selectedProviderId': selectedProviderId,
      'selectedModelName': selectedModelName,
      'requestId': requestId,
    });

    final assistant = _assistants[assistantId];
    if (assistant == null) {
      const error = 'æ‰¾ä¸åˆ°æŒ‡å®šçš„åŠ©æ‰‹é…ç½®';
      _logger.error('åŠ©æ‰‹ä¸å­˜åœ¨', {'assistantId': assistantId});
      _addDebugLog(
        DebugInfo(
          assistantId: assistantId,
          providerId: selectedProviderId,
          modelName: selectedModelName,
          requestBody: {'error': 'assistant_not_found', 'stream': true},
          error: error,
          timestamp: startTime,
        ),
      );
      NotificationService().showError(error);
      yield '[é”™è¯¯] $error';
      return;
    }

    final provider = _providers[selectedProviderId];
    if (provider == null) {
      const error = 'æ‰¾ä¸åˆ°æŒ‡å®šçš„AIæä¾›å•†é…ç½®';
      _logger.error('æä¾›å•†ä¸å­˜åœ¨', {'providerId': selectedProviderId});
      _addDebugLog(
        DebugInfo(
          assistantId: assistantId,
          providerId: selectedProviderId,
          modelName: selectedModelName,
          requestBody: {'error': 'provider_not_found', 'stream': true},
          error: error,
          timestamp: startTime,
        ),
      );
      NotificationService().showError(error);
      yield '[é”™è¯¯] $error';
      return;
    }

    if (!provider.isEnabled) {
      const error = 'AIæä¾›å•†æœªå¯ç”¨ï¼Œè¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½®';
      _logger.warning('æä¾›å•†æœªå¯ç”¨', {'providerId': selectedProviderId});
      _addDebugLog(
        DebugInfo(
          assistantId: assistantId,
          providerId: selectedProviderId,
          modelName: selectedModelName,
          requestBody: {'error': 'provider_disabled', 'stream': true},
          error: error,
          timestamp: startTime,
        ),
      );
      NotificationService().showError(error);
      yield '[é”™è¯¯] $error';
      return;
    }

    final client = _getClient(selectedProviderId);
    if (client == null) {
      const error = 'æ— æ³•åˆ›å»ºAIå®¢æˆ·ç«¯ï¼Œè¯·æ£€æŸ¥é…ç½®';
      _logger.error('å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥', {'providerId': selectedProviderId});
      _addDebugLog(
        DebugInfo(
          assistantId: assistantId,
          providerId: selectedProviderId,
          modelName: selectedModelName,
          requestBody: {'error': 'client_creation_failed', 'stream': true},
          error: error,
          timestamp: startTime,
        ),
      );
      NotificationService().showError(error);
      yield '[é”™è¯¯] $error';
      return;
    }

    // åˆ›å»ºæµæ§åˆ¶å™¨
    final controller = StreamController<String>();
    _streamControllers[requestId] = controller;

    try {
      // æ„å»ºæ¶ˆæ¯åˆ—è¡¨
      final messages = _buildChatMessages(assistant, chatHistory, userMessage);

      // æ„å»ºè¯·æ±‚ä½“ç”¨äºè°ƒè¯•
      final requestBody = {
        'model': selectedModelName,
        'messages': messages
            .map(
              (m) => {
                'role': _getMessageRole(m),
                'content': _getMessageContent(m),
              },
            )
            .toList(),
        'temperature': assistant.temperature,
        'top_p': assistant.topP,
        'max_tokens': assistant.maxTokens,
        'stream': true,
      };

      _logger.aiStreamStart(assistantId, selectedModelName);

      // è®¾ç½®æ¨¡å‹å‚æ•°
      final modelClient = client.bind(
        ChatOpenAIOptions(
          model: selectedModelName,
          temperature: assistant.temperature,
          topP: assistant.topP,
          maxTokens: assistant.maxTokens,
        ),
      );

      // å‘é€æµå¼è¯·æ±‚å¹¶æ·»åŠ è¶…æ—¶
      final stream = modelClient
          .stream(PromptValue.chat(messages))
          .timeout(const Duration(seconds: 20)); // æµå¼è¯·æ±‚ç¨å¾®é•¿ä¸€ç‚¹çš„è¶…æ—¶

      var fullResponse = '';
      var chunkCount = 0;
      bool wasStoppedByUser = false;

      // ç›‘å¬æµæ•°æ®
      final subscription = stream.listen(
        (chunk) {
          // æ£€æŸ¥æ˜¯å¦å·²è¢«åœæ­¢
          if (!_streamControllers.containsKey(requestId)) {
            wasStoppedByUser = true;
            return;
          }

          final content = chunk.output.content;
          if (content.isNotEmpty && !controller.isClosed) {
            fullResponse += content;
            chunkCount++;
            _logger.aiStreamChunk(assistantId, chunkCount, fullResponse.length);
            controller.add(content);
          }
        },
        onError: (error) {
          if (!controller.isClosed &&
              _streamControllers.containsKey(requestId)) {
            final aiError = AiError.fromException(error);
            _logger.aiError(
              assistantId,
              aiError.technicalDetails ?? 'stream error',
              DateTime.now().difference(startTime),
            );

            controller.add('[é”™è¯¯] ${aiError.message}');
            if (aiError.suggestion != null) {
              controller.add('\nğŸ’¡ ${aiError.suggestion}');
            }
          }
          controller.close();
          _cleanup(requestId);
        },
        onDone: () {
          final duration = DateTime.now().difference(startTime);

          if (wasStoppedByUser) {
            _logger.aiStreamStopped(assistantId, chunkCount, duration);
          } else {
            _logger.aiStreamComplete(assistantId, chunkCount, duration);
          }

          _addDebugLog(
            DebugInfo(
              assistantId: assistantId,
              providerId: selectedProviderId,
              modelName: selectedModelName,
              requestBody: requestBody,
              statusCode: 200,
              response: fullResponse,
              timestamp: startTime,
              duration: duration,
              wasStopped: wasStoppedByUser,
            ),
          );

          controller.close();
          _cleanup(requestId);
        },
      );

      _streamSubscriptions[requestId] = subscription;

      // è¿”å›controllerçš„stream
      yield* controller.stream;
    } catch (e) {
      final duration = DateTime.now().difference(startTime);
      final aiError = AiError.fromException(e);

      _logger.aiError(
        assistantId,
        aiError.technicalDetails ?? 'stream setup error',
        duration,
      );

      _addDebugLog(
        DebugInfo(
          assistantId: assistantId,
          providerId: selectedProviderId,
          modelName: selectedModelName,
          requestBody: {
            'model': selectedModelName,
            'temperature': assistant.temperature,
            'top_p': assistant.topP,
            'user_message': userMessage,
            'stream': true,
          },
          error: aiError.technicalDetails,
          timestamp: startTime,
          duration: duration,
        ),
      );

      // æ˜¾ç¤ºç”¨æˆ·å‹å¥½çš„é”™è¯¯é€šçŸ¥
      NotificationService().showError(
        aiError.message,
        actionLabel: aiError.suggestion != null ? 'æŸ¥çœ‹å»ºè®®' : null,
        onActionPressed: aiError.suggestion != null
            ? () {
                NotificationService().showInfo(aiError.suggestion!);
              }
            : null,
      );

      // è¿”å›é”™è¯¯ä¿¡æ¯ï¼Œä¾›èŠå¤©ç•Œé¢æ˜¾ç¤ºåœ¨æ°”æ³¡ä¸­
      yield '[é”™è¯¯] ${aiError.message}';
      if (aiError.suggestion != null) {
        yield '\nğŸ’¡ ${aiError.suggestion}';
      }

      _cleanup(requestId);
    }
  }

  // æ¸…ç†èµ„æº
  void _cleanup(String requestId) {
    _streamControllers.remove(requestId);
    _streamSubscriptions.remove(requestId);
  }

  // æ„å»ºèŠå¤©æ¶ˆæ¯åˆ—è¡¨
  List<ChatMessage> _buildChatMessages(
    AiAssistant assistant,
    List<Message> chatHistory,
    String userMessage,
  ) {
    final messages = <ChatMessage>[];

    // æ·»åŠ ç³»ç»Ÿæç¤º
    if (assistant.systemPrompt.isNotEmpty) {
      messages.add(ChatMessage.system(assistant.systemPrompt));
    }

    // æ·»åŠ ä¸Šä¸‹æ–‡å†å²ï¼ˆé™åˆ¶æ•°é‡ï¼‰
    final contextHistory = chatHistory.take(assistant.contextLength).toList();
    for (final message in contextHistory.reversed) {
      if (message.isFromUser) {
        messages.add(ChatMessage.humanText(message.content));
      } else {
        messages.add(ChatMessage.ai(message.content));
      }
    }

    // æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
    messages.add(ChatMessage.humanText(userMessage));

    return messages;
  }

  // === éªŒè¯å’Œæµ‹è¯• ===

  // æµ‹è¯•æä¾›å•†è¿æ¥
  Future<bool> testProvider(String providerId) async {
    final client = _getClient(providerId);
    if (client == null) return false;

    try {
      // å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
      final response = await client
          .invoke(PromptValue.chat([ChatMessage.humanText('Hello')]))
          .timeout(const Duration(seconds: 10));

      return response.output.content.isNotEmpty;
    } catch (e) {
      _logger.error('æµ‹è¯•æä¾›å•†å¤±è´¥', e);
      return false;
    }
  }

  // è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨ï¼ˆè¿”å›é»˜è®¤æ¨¡å‹åˆ—è¡¨ï¼‰
  Future<List<String>> getAvailableModels(String providerId) async {
    try {
      // langchainæš‚æ—¶æ²¡æœ‰ç›´æ¥çš„æ¨¡å‹åˆ—è¡¨APIï¼Œè¿”å›é»˜è®¤æ¨¡å‹åˆ—è¡¨
      final provider = _providers[providerId];
      return provider?.supportedModels ?? [];
    } catch (e) {
      _logger.error('è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥', e);
      // è¿”å›é»˜è®¤æ¨¡å‹åˆ—è¡¨
      final provider = _providers[providerId];
      return provider?.supportedModels ?? [];
    }
  }
}
