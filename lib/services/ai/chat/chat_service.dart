import 'dart:async';
import '../../../models/ai_provider.dart' as models;
import '../../../models/ai_assistant.dart';
import '../../../models/message.dart';
import '../core/ai_service_base.dart';
import '../core/ai_response_models.dart';
import '../../../ai_dart/ai_dart.dart';

/// èŠå¤©æœåŠ¡ï¼Œè´Ÿè´£å¤„ç†AIèŠå¤©è¯·æ±‚
class ChatService extends AiServiceBase {
  static final ChatService _instance = ChatService._internal();
  factory ChatService() => _instance;
  ChatService._internal();

  final Map<String, AiProviderAdapter> _adapters = {};
  final Map<String, AiServiceStats> _stats = {};
  bool _isInitialized = false;

  @override
  String get serviceName => 'ChatService';

  @override
  Set<AiCapability> get supportedCapabilities => {
    AiCapability.chat,
    AiCapability.streaming,
    AiCapability.toolCalling,
    AiCapability.reasoning,
    AiCapability.vision,
  };

  @override
  Future<void> initialize() async {
    if (_isInitialized) return;

    logger.info('åˆå§‹åŒ–èŠå¤©æœåŠ¡');
    _isInitialized = true;
    logger.info('èŠå¤©æœåŠ¡åˆå§‹åŒ–å®Œæˆ');
  }

  @override
  Future<void> dispose() async {
    logger.info('æ¸…ç†èŠå¤©æœåŠ¡èµ„æº');
    _adapters.clear();
    _stats.clear();
    _isInitialized = false;
  }

  /// å‘é€èŠå¤©æ¶ˆæ¯
  Future<AiResponse> sendMessage({
    required models.AiProvider provider,
    required AiAssistant assistant,
    required String modelName,
    required List<Message> chatHistory,
    required String userMessage,
  }) async {
    await initialize();

    final requestId = _generateRequestId();
    final context = AiRequestContext(
      requestId: requestId,
      config: AiServiceConfig(
        providerId: provider.id,
        modelName: modelName,
        enableStreaming: false,
      ),
    );

    logger.info('å¼€å§‹èŠå¤©è¯·æ±‚', {
      'requestId': requestId,
      'provider': provider.name,
      'model': modelName,
      'assistant': assistant.name,
    });

    try {
      // è·å–æˆ–åˆ›å»ºé€‚é…å™¨
      final adapter = await _getOrCreateAdapter(provider, assistant, modelName);

      // åˆ›å»ºæä¾›å•†å®ä¾‹
      final chatProvider = await adapter.createProvider(enableStreaming: false);

      // æ„å»ºæ¶ˆæ¯åˆ—è¡¨
      final messages = _buildMessageList(adapter, chatHistory, userMessage);

      // å‘é€è¯·æ±‚
      final response = await chatProvider.chatWithTools(messages, null);

      final duration = context.elapsed;

      // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
      _updateStats(provider.id, true, duration);

      logger.info('èŠå¤©è¯·æ±‚å®Œæˆ', {
        'requestId': requestId,
        'duration': '${duration.inMilliseconds}ms',
        'hasThinking': response.thinking != null,
        'usage': response.usage?.totalTokens,
      });

      return AiResponse.success(
        content: response.text ?? '',
        thinking: response.thinking,
        usage: response.usage,
        duration: duration,
        toolCalls: response.toolCalls,
      );
    } catch (e) {
      final duration = context.elapsed;
      _updateStats(provider.id, false, duration);

      logger.error('èŠå¤©è¯·æ±‚å¤±è´¥', {
        'requestId': requestId,
        'error': e.toString(),
        'duration': '${duration.inMilliseconds}ms',
      });

      return AiResponse.error(error: 'èŠå¤©è¯·æ±‚å¤±è´¥: $e', duration: duration);
    }
  }

  /// å‘é€æµå¼èŠå¤©æ¶ˆæ¯
  Stream<AiStreamEvent> sendMessageStream({
    required models.AiProvider provider,
    required AiAssistant assistant,
    required String modelName,
    required List<Message> chatHistory,
    required String userMessage,
  }) async* {
    await initialize();

    final requestId = _generateRequestId();
    final context = AiRequestContext(
      requestId: requestId,
      config: AiServiceConfig(
        providerId: provider.id,
        modelName: modelName,
        enableStreaming: true,
      ),
    );

    logger.info('å¼€å§‹æµå¼èŠå¤©è¯·æ±‚', {
      'requestId': requestId,
      'provider': provider.name,
      'model': modelName,
      'assistant': assistant.name,
    });

    try {
      // è·å–æˆ–åˆ›å»ºé€‚é…å™¨
      final adapter = await _getOrCreateAdapter(provider, assistant, modelName);

      // åˆ›å»ºæµå¼æä¾›å•†å®ä¾‹
      final chatProvider = await adapter.createProvider(enableStreaming: true);

      if (chatProvider is! StreamingChatProvider) {
        yield AiStreamEvent.error('æä¾›å•†ä¸æ”¯æŒæµå¼èŠå¤©');
        return;
      }

      // æ„å»ºæ¶ˆæ¯åˆ—è¡¨
      final messages = _buildMessageList(adapter, chatHistory, userMessage);

      // å‘é€æµå¼è¯·æ±‚
      final streamProvider = chatProvider;
      final stream = streamProvider.chatStream(messages);

      String? finalThinking;
      List<ToolCall>? allToolCalls;

      await for (final event in stream) {
        switch (event) {
          case TextDeltaEvent(delta: final delta):
            yield AiStreamEvent.contentDelta(delta);
            break;
          case ThinkingDeltaEvent(delta: final delta):
            yield AiStreamEvent.thinkingDelta(delta);
            break;
          case ToolCallDeltaEvent(toolCall: final toolCall):
            yield AiStreamEvent.toolCall(toolCall);
            allToolCalls ??= [];
            allToolCalls.add(toolCall);
            break;
          case CompletionEvent(response: final response):
            finalThinking = response.thinking;
            final duration = context.elapsed;

            _updateStats(provider.id, true, duration);

            logger.info('æµå¼èŠå¤©è¯·æ±‚å®Œæˆ', {
              'requestId': requestId,
              'duration': '${duration.inMilliseconds}ms',
              'hasThinking': finalThinking != null,
              'usage': response.usage?.totalTokens,
            });

            yield AiStreamEvent.completed(
              finalThinking: finalThinking,
              usage: response.usage,
              duration: duration,
              allToolCalls: allToolCalls,
            );
            break;
          case ErrorEvent(error: final error):
            final duration = context.elapsed;
            _updateStats(provider.id, false, duration);

            logger.error('æµå¼èŠå¤©è¯·æ±‚å‡ºé”™', {
              'requestId': requestId,
              'error': error.toString(),
              'duration': '${duration.inMilliseconds}ms',
            });

            yield AiStreamEvent.error(error.toString());
            break;
        }
      }
    } catch (e) {
      final duration = context.elapsed;
      _updateStats(provider.id, false, duration);

      logger.error('æµå¼èŠå¤©è¯·æ±‚å¤±è´¥', {
        'requestId': requestId,
        'error': e.toString(),
        'duration': '${duration.inMilliseconds}ms',
      });

      yield AiStreamEvent.error('æµå¼èŠå¤©è¯·æ±‚å¤±è´¥: $e');
    }
  }

  /// æµ‹è¯•æä¾›å•†è¿æ¥
  Future<bool> testProvider({
    required models.AiProvider provider,
    String? modelName,
  }) async {
    await initialize();

    try {
      // åˆ›å»ºæµ‹è¯•åŠ©æ‰‹
      final testAssistant = _createTestAssistant();
      final testModel = modelName ?? _getDefaultModel(provider);

      // åˆ›å»ºé€‚é…å™¨
      final adapter = DefaultAiProviderAdapter(
        provider: provider,
        assistant: testAssistant,
        modelName: testModel,
      );

      // åˆ›å»ºæä¾›å•†å®ä¾‹
      final chatProvider = await adapter.createProvider();

      // å‘é€æµ‹è¯•æ¶ˆæ¯
      final testMessages = [ChatMessage.user('Hello')];
      final response = await chatProvider.chatWithTools(testMessages, null);

      logger.info('æä¾›å•†æµ‹è¯•æˆåŠŸ', {
        'provider': provider.name,
        'model': testModel,
        'responseLength': response.text?.length ?? 0,
      });

      return response.text?.isNotEmpty == true;
    } catch (e) {
      logger.error('æä¾›å•†æµ‹è¯•å¤±è´¥', {
        'provider': provider.name,
        'error': e.toString(),
      });
      return false;
    }
  }

  /// è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯
  AiServiceStats getStats(String providerId) {
    return _stats[providerId] ?? AiServiceStats();
  }

  /// è·å–æˆ–åˆ›å»ºé€‚é…å™¨
  Future<AiProviderAdapter> _getOrCreateAdapter(
    models.AiProvider provider,
    AiAssistant assistant,
    String modelName,
  ) async {
    final key = '${provider.id}_${assistant.id}_$modelName';

    if (!_adapters.containsKey(key)) {
      _adapters[key] = DefaultAiProviderAdapter(
        provider: provider,
        assistant: assistant,
        modelName: modelName,
      );
    }

    return _adapters[key]!;
  }

  /// æ„å»ºæ¶ˆæ¯åˆ—è¡¨
  List<ChatMessage> _buildMessageList(
    AiProviderAdapter adapter,
    List<Message> chatHistory,
    String userMessage,
  ) {
    final messages = <ChatMessage>[];

    // æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
    messages.addAll(adapter.buildSystemMessages());

    // æ·»åŠ èŠå¤©å†å²
    messages.addAll(adapter.convertMessages(chatHistory));

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    messages.add(ChatMessage.user(userMessage));

    return messages;
  }

  /// åˆ›å»ºæµ‹è¯•åŠ©æ‰‹
  AiAssistant _createTestAssistant() {
    return AiAssistant(
      id: 'test-assistant',
      name: 'Test Assistant',
      avatar: 'ğŸ¤–',
      systemPrompt: '',
      temperature: 0.7,
      topP: 1.0,
      maxTokens: 10,
      contextLength: 1,
      streamOutput: false,
      isEnabled: true,
      createdAt: DateTime.now(),
      updatedAt: DateTime.now(),
      description: 'Test assistant for provider validation',
      customHeaders: {},
      customBody: {},
      stopSequences: [],
      frequencyPenalty: 0.0,
      presencePenalty: 0.0,
      enableCodeExecution: false,
      enableImageGeneration: false,
      enableTools: false,
      enableReasoning: false,
      enableVision: false,
      enableEmbedding: false,
    );
  }

  /// è·å–æä¾›å•†çš„ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹ä½œä¸ºé»˜è®¤æ¨¡å‹
  String _getDefaultModel(models.AiProvider provider) {
    // å¦‚æœæä¾›å•†æœ‰é…ç½®çš„æ¨¡å‹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª
    if (provider.models.isNotEmpty) {
      return provider.models.first.name;
    }

    // å¦åˆ™æ ¹æ®æä¾›å•†ç±»å‹è¿”å›å¸¸è§çš„æ¨¡å‹å
    switch (provider.type.name.toLowerCase()) {
      case 'openai':
        return 'gpt-3.5-turbo';
      case 'anthropic':
        return 'claude-3-5-sonnet-20241022';
      case 'google':
        return 'gemini-1.5-flash';
      case 'deepseek':
        return 'deepseek-chat';
      case 'ollama':
        return 'llama3.1';
      case 'xai':
        return 'grok-2-latest';
      case 'groq':
        return 'llama3-8b-8192';
      default:
        return 'default-model';
    }
  }

  /// æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
  void _updateStats(String providerId, bool success, Duration duration) {
    final currentStats = _stats[providerId] ?? AiServiceStats();

    _stats[providerId] = currentStats.copyWith(
      totalRequests: currentStats.totalRequests + 1,
      successfulRequests: success
          ? currentStats.successfulRequests + 1
          : currentStats.successfulRequests,
      failedRequests: success
          ? currentStats.failedRequests
          : currentStats.failedRequests + 1,
      totalDuration: currentStats.totalDuration + duration,
      lastRequestTime: DateTime.now(),
    );
  }

  /// ç”Ÿæˆè¯·æ±‚ID
  String _generateRequestId() {
    return 'chat_${DateTime.now().millisecondsSinceEpoch}_${_stats.length}';
  }
}
