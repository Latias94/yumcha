import '../src/rust/api/ai_chat.dart' as genai;
import '../models/ai_provider.dart' as models;
import '../models/ai_assistant.dart';
import '../models/message.dart';
import 'logger_service.dart';

/// AI è¯·æ±‚å“åº”ç»“æœ
class AiRequestResult {
  final String? content;
  final String? error;
  final Duration? duration;
  final genai.TokenUsage? usage;
  final bool wasCancelled;

  const AiRequestResult({
    this.content,
    this.error,
    this.duration,
    this.usage,
    this.wasCancelled = false,
  });

  bool get isSuccess => content != null && error == null;
}

/// AI æµå¼è¯·æ±‚äº‹ä»¶
class AiStreamEvent {
  final String? content;
  final String? error;
  final bool isDone;
  final genai.TokenUsage? usage;
  final bool wasCancelled;

  const AiStreamEvent({
    this.content,
    this.error,
    this.isDone = false,
    this.usage,
    this.wasCancelled = false,
  });

  bool get isContent => content != null && !isDone;
  bool get isError => error != null;
}

/// AI è¯·æ±‚æœåŠ¡ - ä¸“é—¨å¤„ç†ä¸ genai crate çš„äº¤äº’
class AiRequestService {
  static final AiRequestService _instance = AiRequestService._internal();
  factory AiRequestService() => _instance;
  AiRequestService._internal();

  final LoggerService _logger = LoggerService();
  final Map<String, genai.AiChatClient> _clients = {};

  /// å°†åº”ç”¨å†…çš„ AiProvider è½¬æ¢ä¸º genai çš„ AiProvider
  genai.AiProvider convertProvider(models.AiProvider appProvider) {
    switch (appProvider.type) {
      case models.ProviderType.openai:
        return const genai.AiProvider.openAi();
      case models.ProviderType.anthropic:
        return const genai.AiProvider.anthropic();
      case models.ProviderType.google:
        return const genai.AiProvider.gemini();
      case models.ProviderType.ollama:
        return const genai.AiProvider.ollama();
      case models.ProviderType.custom:
        return genai.AiProvider.custom(name: appProvider.name);
    }
  }

  /// æ„å»º AI èŠå¤©é€‰é¡¹
  genai.AiChatOptions buildChatOptions(
    models.AiProvider provider,
    AiAssistant assistant,
    String modelName,
  ) {
    return genai.AiChatOptions(
      model: modelName,
      apiKey: provider.apiKey,
      baseUrl: provider.baseUrl?.isNotEmpty == true ? provider.baseUrl : null,
      temperature: assistant.temperature,
      topP: assistant.topP,
      maxTokens: assistant.maxTokens,
      systemPrompt: assistant.systemPrompt.isNotEmpty
          ? assistant.systemPrompt
          : null,
      stopSequences: assistant.stopSequences.isNotEmpty
          ? assistant.stopSequences
          : null,
    );
  }

  /// æ„å»ºèŠå¤©æ¶ˆæ¯åˆ—è¡¨
  List<genai.ChatMessage> buildChatMessages(
    AiAssistant assistant,
    List<Message> chatHistory,
    String userMessage,
  ) {
    final messages = <genai.ChatMessage>[];

    // æ·»åŠ ç³»ç»Ÿæç¤ºï¼ˆå¦‚æœæœ‰ï¼‰
    if (assistant.systemPrompt.isNotEmpty) {
      messages.add(
        genai.ChatMessage(
          role: genai.ChatRole.system,
          content: assistant.systemPrompt,
        ),
      );
    }

    // æ·»åŠ ä¸Šä¸‹æ–‡å†å²ï¼ˆé™åˆ¶æ•°é‡ï¼‰
    final contextHistory = chatHistory.take(assistant.contextLength).toList();
    for (final message in contextHistory.reversed) {
      if (message.isFromUser) {
        messages.add(
          genai.ChatMessage(
            role: genai.ChatRole.user,
            content: message.content,
          ),
        );
      } else {
        messages.add(
          genai.ChatMessage(
            role: genai.ChatRole.assistant,
            content: message.content,
          ),
        );
      }
    }

    // æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
    messages.add(
      genai.ChatMessage(role: genai.ChatRole.user, content: userMessage),
    );

    return messages;
  }

  /// è·å–æˆ–åˆ›å»º AI èŠå¤©å®¢æˆ·ç«¯
  genai.AiChatClient _getClient(
    models.AiProvider provider,
    AiAssistant assistant,
    String modelName,
  ) {
    final clientKey = '${provider.id}_$modelName';

    if (_clients.containsKey(clientKey)) {
      return _clients[clientKey]!;
    }

    final aiProvider = convertProvider(provider);
    final options = buildChatOptions(provider, assistant, modelName);

    final client = genai.AiChatClient(provider: aiProvider, options: options);

    _clients[clientKey] = client;
    _logger.info('åˆ›å»º AI å®¢æˆ·ç«¯: ${provider.name} -> $modelName');

    return client;
  }

  /// æ¸…é™¤å®¢æˆ·ç«¯ç¼“å­˜
  void clearClientCache([String? providerId]) {
    if (providerId != null) {
      _clients.removeWhere((key, _) => key.startsWith(providerId));
    } else {
      _clients.clear();
    }
    _logger.info('æ¸…é™¤å®¢æˆ·ç«¯ç¼“å­˜: ${providerId ?? 'å…¨éƒ¨'}');
  }

  /// éªŒè¯æä¾›å•†é…ç½®
  String? _validateProvider(models.AiProvider provider) {
    if (!provider.isEnabled) {
      return 'AIæä¾›å•†æœªå¯ç”¨';
    }

    if (provider.apiKey.isEmpty &&
        provider.type != models.ProviderType.ollama) {
      return 'APIå¯†é’¥ä¸èƒ½ä¸ºç©º';
    }

    // åŸºæœ¬çš„ API å¯†é’¥æ ¼å¼éªŒè¯
    switch (provider.type) {
      case models.ProviderType.openai:
      case models.ProviderType.custom:
        if (!provider.apiKey.startsWith('sk-') &&
            provider.apiKey != 'sk-test-example-key') {
          return 'OpenAI APIå¯†é’¥æ ¼å¼é”™è¯¯ï¼Œåº”ä»¥ sk- å¼€å¤´';
        }
        break;
      case models.ProviderType.anthropic:
        if (!provider.apiKey.startsWith('sk-ant-')) {
          return 'Anthropic APIå¯†é’¥æ ¼å¼é”™è¯¯ï¼Œåº”ä»¥ sk-ant- å¼€å¤´';
        }
        break;
      default:
        break;
    }

    return null;
  }

  /// æ„å»ºè¯·æ±‚ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆç”¨äºé”™è¯¯æŠ¥å‘Šï¼‰
  Map<String, dynamic> _buildRequestContext(
    models.AiProvider provider,
    AiAssistant assistant,
    String modelName,
    String userMessage,
  ) {
    return {
      'provider': {
        'name': provider.name,
        'type': provider.type.name,
        'baseUrl': provider.baseUrl ?? 'é»˜è®¤ç«¯ç‚¹',
        'apiKeyPrefix': provider.apiKey.isNotEmpty
            ? provider.apiKey.length > 8
                  ? '${provider.apiKey.substring(0, 8)}...'
                  : '${provider.apiKey}...'
            : 'æœªè®¾ç½®',
      },
      'model': modelName,
      'assistant': assistant.name,
      'parameters': {
        'temperature': assistant.temperature,
        'topP': assistant.topP,
        'maxTokens': assistant.maxTokens,
        'systemPrompt': assistant.systemPrompt.isNotEmpty
            ? assistant.systemPrompt.length > 50
                  ? '${assistant.systemPrompt.substring(0, 50)}...'
                  : assistant.systemPrompt
            : 'æ— ',
      },
      'message': userMessage.length > 100
          ? '${userMessage.substring(0, 100)}...'
          : userMessage,
    };
  }

  /// å‘é€å•æ¬¡èŠå¤©è¯·æ±‚
  Future<AiRequestResult> sendChatRequest({
    required models.AiProvider provider,
    required AiAssistant assistant,
    required String modelName,
    required List<Message> chatHistory,
    required String userMessage,
  }) async {
    final startTime = DateTime.now();
    final requestContext = _buildRequestContext(
      provider,
      assistant,
      modelName,
      userMessage,
    );

    try {
      // éªŒè¯æä¾›å•†é…ç½®
      final validationError = _validateProvider(provider);
      if (validationError != null) {
        _logger.error('AI è¯·æ±‚éªŒè¯å¤±è´¥', {
          'error': validationError,
          'context': requestContext,
        });
        return AiRequestResult(error: validationError);
      }

      _logger.info('å¼€å§‹ AI èŠå¤©è¯·æ±‚', {
        'provider': provider.name,
        'model': modelName,
        'assistant': assistant.name,
        'baseUrl': provider.baseUrl ?? 'é»˜è®¤ç«¯ç‚¹',
      });

      // è·å–å®¢æˆ·ç«¯
      final client = _getClient(provider, assistant, modelName);

      // æ„å»ºæ¶ˆæ¯
      final messages = buildChatMessages(assistant, chatHistory, userMessage);

      // å‘é€è¯·æ±‚
      final response = await client.chat(messages: messages);
      final duration = DateTime.now().difference(startTime);

      _logger.info('AI èŠå¤©è¯·æ±‚å®Œæˆ', {
        'duration': '${duration.inMilliseconds}ms',
        'usage': response.usage?.totalTokens,
        'responseLength': response.content.length,
      });

      return AiRequestResult(
        content: response.content,
        duration: duration,
        usage: response.usage,
      );
    } catch (e) {
      final duration = DateTime.now().difference(startTime);
      final errorMessage = _handleError(e, requestContext);

      _logger.error('AI èŠå¤©è¯·æ±‚å¤±è´¥', {
        'error': e.toString(),
        'duration': '${duration.inMilliseconds}ms',
        'context': requestContext,
      });

      return AiRequestResult(error: errorMessage, duration: duration);
    }
  }

  /// å‘é€æµå¼èŠå¤©è¯·æ±‚
  Stream<AiStreamEvent> sendChatStreamRequest({
    required models.AiProvider provider,
    required AiAssistant assistant,
    required String modelName,
    required List<Message> chatHistory,
    required String userMessage,
  }) async* {
    final startTime = DateTime.now();
    final requestContext = _buildRequestContext(
      provider,
      assistant,
      modelName,
      userMessage,
    );

    try {
      // éªŒè¯æä¾›å•†é…ç½®
      final validationError = _validateProvider(provider);
      if (validationError != null) {
        _logger.error('AI æµå¼è¯·æ±‚éªŒè¯å¤±è´¥', {
          'error': validationError,
          'context': requestContext,
        });
        yield AiStreamEvent(error: validationError);
        return;
      }

      _logger.info('å¼€å§‹ AI æµå¼èŠå¤©è¯·æ±‚', {
        'provider': provider.name,
        'model': modelName,
        'assistant': assistant.name,
        'baseUrl': provider.baseUrl ?? 'é»˜è®¤ç«¯ç‚¹',
      });

      // è·å–å®¢æˆ·ç«¯
      final client = _getClient(provider, assistant, modelName);

      // æ„å»ºæ¶ˆæ¯
      final messages = buildChatMessages(assistant, chatHistory, userMessage);

      // å‘é€æµå¼è¯·æ±‚
      final stream = client.chatStream(messages: messages);

      await for (final event in stream) {
        switch (event) {
          case genai.ChatStreamEvent_Start():
            _logger.debug('AI æµå¼èŠå¤©å¼€å§‹');
            break;

          case genai.ChatStreamEvent_Content(:final content):
            yield AiStreamEvent(content: content);
            break;

          case genai.ChatStreamEvent_Done(:final totalContent, :final usage):
            final duration = DateTime.now().difference(startTime);

            _logger.info('AI æµå¼èŠå¤©å®Œæˆ', {
              'duration': '${duration.inMilliseconds}ms',
              'totalLength': totalContent.length,
              'usage': usage?.totalTokens,
            });

            yield AiStreamEvent(isDone: true, usage: usage);
            break;

          case genai.ChatStreamEvent_Error(:final message):
            _logger.error('AI æµå¼èŠå¤©é”™è¯¯', {
              'error': message,
              'context': requestContext,
            });
            yield AiStreamEvent(
              error: _formatDetailedError(message, requestContext),
            );
            break;
        }
      }
    } catch (e) {
      final duration = DateTime.now().difference(startTime);
      final errorMessage = _handleError(e, requestContext);

      _logger.error('AI æµå¼èŠå¤©è¯·æ±‚å¤±è´¥', {
        'error': e.toString(),
        'duration': '${duration.inMilliseconds}ms',
        'context': requestContext,
      });

      yield AiStreamEvent(error: errorMessage);
    }
  }

  /// æµ‹è¯•æä¾›å•†è¿æ¥
  Future<bool> testProvider({
    required models.AiProvider provider,
    String? modelName,
  }) async {
    final testModel =
        modelName ?? provider.models.firstOrNull?.name ?? 'gpt-3.5-turbo';
    final requestContext = {
      'provider': provider.name,
      'type': provider.type.name,
      'baseUrl': provider.baseUrl ?? 'é»˜è®¤ç«¯ç‚¹',
      'model': testModel,
    };

    try {
      // éªŒè¯æä¾›å•†é…ç½®
      final validationError = _validateProvider(provider);
      if (validationError != null) {
        _logger.warning('æä¾›å•†éªŒè¯å¤±è´¥', {
          'error': validationError,
          'context': requestContext,
        });
        return false;
      }

      _logger.info('å¼€å§‹æµ‹è¯•æä¾›å•†', requestContext);

      final options = genai.AiChatOptions(
        model: testModel,
        apiKey: provider.apiKey,
        baseUrl: provider.baseUrl?.isNotEmpty == true ? provider.baseUrl : null,
        temperature: 0.7,
        maxTokens: 10, // é™åˆ¶tokenä»¥èŠ‚çœè´¹ç”¨
      );

      final client = genai.AiChatClient(
        provider: convertProvider(provider),
        options: options,
      );

      final messages = [
        genai.ChatMessage(role: genai.ChatRole.user, content: 'Hi'),
      ];

      // å‘é€ç®€å•æµ‹è¯•è¯·æ±‚ï¼Œè®¾ç½®çŸ­è¶…æ—¶
      final response = await client.chat(messages: messages);

      _logger.info('æä¾›å•†æµ‹è¯•æˆåŠŸ', {
        ...requestContext,
        'responseLength': response.content.length,
      });

      return response.content.isNotEmpty;
    } catch (e) {
      _logger.error('æä¾›å•†æµ‹è¯•å¤±è´¥', {
        'error': e.toString(),
        'context': requestContext,
      });
      return false;
    }
  }

  /// å¤„ç†é”™è¯¯ä¿¡æ¯ï¼ˆå¢å¼ºç‰ˆï¼ŒåŒ…å«è¯·æ±‚ä¸Šä¸‹æ–‡ï¼‰
  String _handleError(dynamic error, Map<String, dynamic> requestContext) {
    final errorMessage = error.toString().toLowerCase();
    String userFriendlyMessage;

    if (errorMessage.contains('unauthorized') ||
        errorMessage.contains('invalid api key')) {
      userFriendlyMessage = 'APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®';
    } else if (errorMessage.contains('rate limit') ||
        errorMessage.contains('too many requests')) {
      userFriendlyMessage = 'è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åé‡è¯•';
    } else if (errorMessage.contains('insufficient_quota') ||
        errorMessage.contains('quota exceeded')) {
      userFriendlyMessage = 'è´¦æˆ·ä½™é¢ä¸è¶³ï¼Œè¯·æ£€æŸ¥è®¢é˜…çŠ¶æ€';
    } else if (errorMessage.contains('model') &&
        errorMessage.contains('not found')) {
      userFriendlyMessage = 'æ¨¡å‹ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥æ¨¡å‹åç§°';
    } else if (errorMessage.contains('timeout')) {
      userFriendlyMessage = 'è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥';
    } else if (errorMessage.contains('network') ||
        errorMessage.contains('connection')) {
      userFriendlyMessage = 'ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®';
    } else if (errorMessage.contains('404') ||
        errorMessage.contains('not found')) {
      userFriendlyMessage = 'APIç«¯ç‚¹ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥æœåŠ¡å™¨åœ°å€';
    } else {
      userFriendlyMessage = 'è¯·æ±‚å¤±è´¥';
    }

    return _formatDetailedError(
      userFriendlyMessage,
      requestContext,
      error.toString(),
    );
  }

  /// æ ¼å¼åŒ–è¯¦ç»†é”™è¯¯ä¿¡æ¯
  String _formatDetailedError(
    String message,
    Map<String, dynamic> requestContext, [
    String? technicalError,
  ]) {
    final buffer = StringBuffer();
    buffer.writeln('âŒ $message');
    buffer.writeln();
    buffer.writeln('ğŸ“¡ è¯·æ±‚ä¿¡æ¯:');
    buffer.writeln(
      '   æä¾›å•†: ${requestContext['provider']?['name'] ?? 'Unknown'}',
    );
    buffer.writeln(
      '   ç«¯ç‚¹: ${requestContext['provider']?['baseUrl'] ?? requestContext['baseUrl'] ?? 'Unknown'}',
    );
    buffer.writeln('   æ¨¡å‹: ${requestContext['model'] ?? 'Unknown'}');

    if (requestContext['parameters'] != null) {
      final params = requestContext['parameters'] as Map<String, dynamic>;
      buffer.writeln(
        '   å‚æ•°: temperature=${params['temperature']}, maxTokens=${params['maxTokens']}',
      );
    }

    if (technicalError != null) {
      buffer.writeln();
      buffer.writeln('ğŸ”§ æŠ€æœ¯è¯¦æƒ…:');
      buffer.writeln(
        '   ${technicalError.length > 200 ? '${technicalError.substring(0, 200)}...' : technicalError}',
      );
    }

    return buffer.toString();
  }
}
